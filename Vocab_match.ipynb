{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pattern in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (3.6)\n",
      "Requirement already satisfied: cherrypy in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (18.8.0)\n",
      "Requirement already satisfied: nltk in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (3.7)\n",
      "Requirement already satisfied: backports.csv in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (1.0.7)\n",
      "Requirement already satisfied: scipy in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (1.7.3)\n",
      "Requirement already satisfied: numpy in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (1.22.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (4.11.1)\n",
      "Requirement already satisfied: requests in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (2.28.1)\n",
      "Requirement already satisfied: python-docx in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (0.8.11)\n",
      "Requirement already satisfied: feedparser in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (6.0.10)\n",
      "Requirement already satisfied: future in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (0.18.2)\n",
      "Requirement already satisfied: lxml in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (4.9.1)\n",
      "Requirement already satisfied: pdfminer.six in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (20221105)\n",
      "Requirement already satisfied: mysqlclient in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pattern) (2.1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from beautifulsoup4->pattern) (2.3.2.post1)\n",
      "Requirement already satisfied: zc.lockfile in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cherrypy->pattern) (2.0)\n",
      "Requirement already satisfied: more-itertools in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cherrypy->pattern) (9.0.0)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cherrypy->pattern) (9.0.0)\n",
      "Requirement already satisfied: portend>=2.1.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cherrypy->pattern) (3.1.0)\n",
      "Requirement already satisfied: jaraco.collections in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cherrypy->pattern) (3.8.0)\n",
      "Requirement already satisfied: sgmllib3k in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from feedparser->pattern) (1.0.0)\n",
      "Requirement already satisfied: click in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk->pattern) (8.0.4)\n",
      "Requirement already satisfied: tqdm in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk->pattern) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk->pattern) (2022.3.15)\n",
      "Requirement already satisfied: joblib in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk->pattern) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pdfminer.six->pattern) (2.1.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pdfminer.six->pattern) (38.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from requests->pattern) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from requests->pattern) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from requests->pattern) (1.26.13)\n",
      "Requirement already satisfied: jaraco.functools in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cheroot>=8.2.1->cherrypy->pattern) (3.5.2)\n",
      "Requirement already satisfied: six>=1.11.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cheroot>=8.2.1->cherrypy->pattern) (1.16.0)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.1)\n",
      "Requirement already satisfied: tempora>=1.8 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from portend>=2.1.1->cherrypy->pattern) (5.1.0)\n",
      "Requirement already satisfied: jaraco.text in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from jaraco.collections->cherrypy->pattern) (3.11.0)\n",
      "Requirement already satisfied: jaraco.classes in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from jaraco.collections->cherrypy->pattern) (3.2.3)\n",
      "Requirement already satisfied: setuptools in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from zc.lockfile->cherrypy->pattern) (65.5.0)\n",
      "Requirement already satisfied: pycparser in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
      "Requirement already satisfied: pytz in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2022.1)\n",
      "Requirement already satisfied: inflect in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (6.0.2)\n",
      "Requirement already satisfied: autocommand in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.2.2)\n",
      "Requirement already satisfied: jaraco.context>=4.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (4.2.0)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (1.10.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (4.4.0)\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/clips/pattern/issues/203\n",
    "!pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyinflect\n",
      "  Downloading pyinflect-0.5.1-py3-none-any.whl (703 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m703.5/703.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyinflect\n",
      "Successfully installed pyinflect-0.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyinflect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "import nltk\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "#python -m spacy download en\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "import pattern\n",
    "from pattern.en import lemma, lexeme\n",
    "from pattern.en import parse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./Data/incompleted_keywords.txt\", \"r\")\n",
    "file_data = file.read()\n",
    "\n",
    "words = file_data.split(',')\n",
    "\n",
    "incomplete_keyword_list = []\n",
    "ps = PorterStemmer()\n",
    "\n",
    "for word in words:\n",
    "    word_clean = word.replace('\\\"', '')\n",
    "    word_root = ps.stem(word_clean)\n",
    "    #print(word_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abus\n",
      "abus\n",
      "accident\n",
      " \n",
      "accident\n",
      "adverse\n",
      " \n",
      "adverse\n",
      "african\n",
      " \n",
      "african\n",
      "age\n",
      " \n",
      "age\n",
      "agitate\n",
      " \n",
      "agitate\n",
      "agon\n",
      " \n",
      "agon\n",
      "american\n",
      " \n",
      "american\n",
      "anger\n",
      " \n",
      "anger\n",
      "angry\n",
      " \n",
      "angry\n",
      "apolo\n",
      " \n",
      "apolo\n",
      "argu\n",
      " \n",
      "argu\n",
      "assault\n",
      " \n",
      "assault\n",
      "attack\n",
      " \n",
      "attack\n",
      "attorney\n",
      " \n",
      "attorney\n",
      "awful\n",
      " \n",
      "awful\n",
      "bad\n",
      " \n",
      "bad\n",
      "battery\n",
      " \n",
      "battery\n",
      "black\n",
      " \n",
      "black\n",
      "blackmail\n",
      " \n",
      "blackmail\n",
      "blame\n",
      " \n",
      "blame\n",
      "blatant\n",
      " \n",
      "blatant\n",
      "bleed\n",
      " \n",
      "bleed\n",
      "blood\n",
      " \n",
      "blood\n",
      "blow\n",
      " \n",
      "blow\n",
      "bomb\n",
      " \n",
      "bomb\n",
      "brown\n",
      " \n",
      "brown\n",
      "bruise\n",
      " \n",
      "bruise\n",
      "burn\n",
      " \n",
      "burn\n",
      "call\n",
      " \n",
      "call\n",
      "cancel\n",
      " \n",
      "cancel\n",
      "careless\n",
      " \n",
      "careless\n",
      "caucasian\n",
      " \n",
      "caucasian\n",
      "charge\n",
      " \n",
      "charge\n",
      "claim\n",
      " \n",
      "claim\n",
      "compl\n",
      " \n",
      "compl\n",
      "confidential\n",
      " \n",
      "confidential\n",
      "consent\n",
      " \n",
      "consent\n",
      "contact\n",
      " \n",
      "contact\n",
      "cops\n",
      " \n",
      "cop\n",
      "court\n",
      " \n",
      "court\n",
      "criminal\n",
      " \n",
      "criminal\n",
      "cruel\n",
      " \n",
      "cruel\n",
      "custody\n",
      " \n",
      "custody\n",
      "damage\n",
      " \n",
      "damage\n",
      "danger\n",
      " \n",
      "danger\n",
      "dead\n",
      " \n",
      "dead\n",
      "death\n",
      " \n",
      "death\n",
      "delay\n",
      " \n",
      "delay\n",
      "demean\n",
      " \n",
      "demean\n",
      "derelict\n",
      " \n",
      "derelict\n",
      "deserve\n",
      " \n",
      "deserve\n",
      "destr\n",
      " \n",
      "destr\n",
      "died\n",
      " \n",
      "die\n",
      "dign\n",
      " \n",
      "dign\n",
      "directive\n",
      " \n",
      "directive\n",
      "dirt\n",
      " \n",
      "dirt\n",
      "discrimin\n",
      " \n",
      "discrimin\n",
      "dismissive\n",
      " \n",
      "dismissive\n",
      "electrocute\n",
      " \n",
      "electrocute\n",
      "emergency\n",
      " \n",
      "emergency\n",
      "error\n",
      " \n",
      "error\n",
      "equal\n",
      " \n",
      "equal\n",
      "equity\n",
      " \n",
      "equity\n",
      "fail\n",
      " \n",
      "fail\n",
      "fault\n",
      " \n",
      "fault\n",
      "fight\n",
      " \n",
      "fight\n",
      "fired\n",
      " \n",
      "fire\n",
      "fix\n",
      " \n",
      "fix\n",
      "flippan\n",
      " \n",
      "flippan\n",
      "forgot\n",
      " \n",
      "forget\n",
      "fought\n",
      " \n",
      "fight\n",
      "fraud\n",
      " \n",
      "fraud\n",
      "gay\n",
      " \n",
      "gay\n",
      "gender\n",
      " \n",
      "gender\n",
      "grievance\n",
      " \n",
      "grievance\n",
      "gun\n",
      " \n",
      "gun\n",
      "hack\n",
      " \n",
      "hack\n",
      "harm\n",
      " \n",
      "harm\n",
      "hate\n",
      " \n",
      "hate\n",
      "help\n",
      " \n",
      "help\n",
      "hipaa\n",
      " \n",
      "hipaa\n",
      "hippa\n",
      " \n",
      "hippa\n",
      "hispanic\n",
      " \n",
      "hispanic\n",
      "horr\n",
      " \n",
      "horr\n",
      "hot\n",
      " \n",
      "hot\n",
      "hurt\n",
      " \n",
      "hurt\n",
      "ignore\n",
      " \n",
      "ignore\n",
      "illegal\n",
      " \n",
      "illegal\n",
      "inadequate\n",
      " \n",
      "inadequate\n",
      "inappro\n",
      " \n",
      "inappro\n",
      "inattent\n",
      " \n",
      "inattent\n",
      "incident\n",
      " \n",
      "incident\n",
      "incompetent\n",
      " \n",
      "incompetent\n",
      "incorrect\n",
      " \n",
      "incorrect\n",
      "infect\n",
      " \n",
      "infect\n",
      "injur\n",
      " \n",
      "injur\n",
      "insult\n",
      " \n",
      "insult\n",
      "irresponsibl\n",
      " \n",
      "irresponsibl\n",
      "jail\n",
      " \n",
      "jail\n",
      "jeopard\n",
      " \n",
      "jeopard\n",
      "kill\n",
      " \n",
      "kill\n",
      "lack\n",
      " \n",
      "lack\n",
      "law\n",
      " \n",
      "law\n",
      "legal\n",
      " \n",
      "legal\n",
      "lesbian\n",
      " \n",
      "lesbian\n",
      "liable\n",
      " \n",
      "liable\n",
      "litigat\n",
      " \n",
      "litigat\n",
      "malpractice\n",
      " \n",
      "malpractice\n",
      "massac\n",
      " \n",
      "massac\n",
      "man\n",
      " \n",
      "man\n",
      "mean\n",
      " \n",
      "mean\n",
      "media\n",
      " \n",
      "medium\n",
      "men\n",
      " \n",
      "man\n",
      "minorit\n",
      " \n",
      "minorit\n",
      "mis\n",
      " \n",
      "mis\n",
      "MRSA\n",
      " \n",
      "MRSA\n",
      "murder\n",
      " \n",
      "murder\n",
      "negl\n",
      " \n",
      "negl\n",
      "nightmare\n",
      " \n",
      "nightmare\n",
      "no\n",
      " \n",
      "no\n",
      "offen\n",
      " \n",
      "offen\n",
      "overdose\n",
      " \n",
      "overdose\n",
      "pain\n",
      " \n",
      "pain\n",
      "patroniz\n",
      " \n",
      "patroniz\n",
      "pistol\n",
      " \n",
      "pistol\n",
      "police\n",
      " \n",
      "police\n",
      "priva\n",
      " \n",
      "priva\n",
      "problem\n",
      " \n",
      "problem\n",
      "question\n",
      " \n",
      "question\n",
      "race\n",
      " \n",
      "race\n",
      "racism\n",
      " \n",
      "racism\n",
      "racist\n",
      " \n",
      "racist\n",
      "rape\n",
      " \n",
      "rape\n",
      "reckless\n",
      " \n",
      "reckless\n",
      "recover\n",
      " \n",
      "recover\n",
      "regret\n",
      " \n",
      "regret\n",
      "respect\n",
      " \n",
      "respect\n",
      "ridiculous\n",
      " \n",
      "ridiculous\n",
      "rifle\n",
      " \n",
      "rifle\n",
      "rights\n",
      " \n",
      "right\n",
      "risk\n",
      " \n",
      "risk\n",
      "rude\n",
      " \n",
      "rude\n",
      "ruin\n",
      " \n",
      "ruin\n",
      "safe\n",
      " \n",
      "safe\n",
      "secur\n",
      " \n",
      "secur\n",
      "sepsis\n",
      " \n",
      "sepsis\n",
      "severe\n",
      " \n",
      "severe\n",
      "sexual\n",
      " \n",
      "sexual\n",
      "shock\n",
      " \n",
      "shock\n",
      "shoot\n",
      " \n",
      "shoot\n",
      "slay\n",
      " \n",
      "slay\n",
      "sorry\n",
      " \n",
      "sorry\n",
      "stab\n",
      " \n",
      "stab\n",
      "steal\n",
      " \n",
      "steal\n",
      "stole\n",
      " \n",
      "steal\n",
      "stop\n",
      " \n",
      "stop\n",
      "sue\n",
      " \n",
      "sue\n",
      "suffer\n",
      " \n",
      "suffer\n",
      "suicid\n",
      " \n",
      "suicid\n",
      "suit\n",
      " \n",
      "suit\n",
      "terr\n",
      " \n",
      "terr\n",
      "threat\n",
      " \n",
      "threat\n",
      "trag\n",
      " \n",
      "trag\n",
      "transgr\n",
      " \n",
      "transgr\n",
      "trauma\n",
      " \n",
      "trauma\n",
      "travesty\n",
      " \n",
      "travesty\n",
      "trouble\n",
      " \n",
      "trouble\n",
      "un\n",
      " \n",
      "un\n",
      "upset\n",
      " \n",
      "upset\n",
      "viol\n",
      " \n",
      "viol\n",
      "waste\n",
      " \n",
      "waste\n",
      "weapon\n",
      " \n",
      "weapon\n",
      "white\n",
      " \n",
      "white\n",
      "woman\n",
      " \n",
      "woman\n",
      "women\n",
      " \n",
      "woman\n",
      "wound\n",
      " \n",
      "wound\n",
      "wrath\n",
      " \n",
      "wrath\n",
      "wrong\n",
      " \n",
      "wrong\n",
      "414\n",
      " \n",
      "414\n",
      "262\n",
      " \n",
      "262\n",
      "0\n",
      " \n",
      "0\n",
      "-1\n",
      " \n",
      "-1\n",
      "-2\n",
      " \n",
      "-2\n",
      "-3\n",
      " \n",
      "-3\n",
      "-4\n",
      " \n",
      "-4\n",
      "-5\n",
      " \n",
      "-5\n",
      "-6\n",
      " \n",
      "-6\n",
      "-7\n",
      " \n",
      "-7\n",
      "-8\n",
      " \n",
      "-8\n",
      "-9\n",
      " \n",
      "-9\n",
      "0\n",
      " \n",
      "0\n",
      "0.1\n",
      " \n",
      "0.1\n",
      "0.2\n",
      " \n",
      "0.2\n",
      "0.3\n",
      " \n",
      "0.3\n",
      "0.4\n",
      " \n",
      "0.4\n",
      "0.5\n",
      " \n",
      "0.5\n",
      "0.6\n",
      " \n",
      "0.6\n",
      "0.7\n",
      " \n",
      "0.7\n",
      "0.8\n",
      " \n",
      "0.8\n",
      "0.9\n",
      " \n",
      "0.9\n",
      "@\n",
      " \n",
      "@\n",
      "count ::  202\n"
     ]
    }
   ],
   "source": [
    "file = open(\"./Data/keywords.txt\", \"r\")\n",
    "file_data = file.read()\n",
    "\n",
    "words = file_data.split(',')\n",
    "count = 0\n",
    "for word in words:\n",
    "    count = count +1\n",
    "    word_clean = word.replace('\\\"', '')\n",
    "    doc = nlp(word_clean)\n",
    "    print(word_clean.strip())\n",
    "    for token in doc:\n",
    "        print(token.lemma_)\n",
    "\n",
    "print('count :: ', count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abus\n",
      "['abu', 'abus', 'abuing', 'abued']\n",
      " accident\n",
      "[' accident', ' accidents', ' accidenting', ' accidented']\n",
      " adverse\n",
      "[' adverse', ' adverses', ' adversing', ' adversed']\n",
      " african\n",
      "[' african', ' africans', ' africanning', ' africanned']\n",
      " age\n",
      "[' age', ' ages', ' aging', ' aged']\n",
      " agitate\n",
      "[' agitate', ' agitates', ' agitating', ' agitated']\n",
      " agon\n",
      "[' agon', ' agons', ' agonning', ' agonned']\n",
      " american\n",
      "[' american', ' americans', ' americanning', ' americanned']\n",
      " anger\n",
      "[' anger', ' angers', ' angerring', ' angerred']\n",
      " angry\n",
      "[' angry', ' angries', ' angrying', ' angried']\n",
      " apolo\n",
      "[' apolo', ' apolos', ' apoloing', ' apoloed']\n",
      " argu\n",
      "[' argu', ' argus', ' arguing', ' argued']\n",
      " assault\n",
      "[' assault', ' assaults', ' assaulting', ' assaulted']\n",
      " attack\n",
      "[' attack', ' attacks', ' attacking', ' attacked']\n",
      " attorney\n",
      "[' attorney', ' attorneys', ' attorneying', ' attorneyed']\n",
      " awful\n",
      "[' awful', ' awfuls', ' awfulling', ' awfulled']\n",
      " bad\n",
      "[' bad', ' bads', ' badding', ' badded']\n",
      " battery\n",
      "[' battery', ' batteries', ' batterying', ' batteried']\n",
      " black\n",
      "[' black', ' blacks', ' blacking', ' blacked']\n",
      " blackmail\n",
      "[' blackmail', ' blackmails', ' blackmailing', ' blackmailed']\n",
      " blame\n",
      "[' blame', ' blames', ' blaming', ' blamed']\n",
      " blatant\n",
      "[' blatant', ' blatants', ' blatanting', ' blatanted']\n",
      " bleed\n",
      "[' blee', ' blees', ' bleeing', ' bleeed']\n",
      " blood\n",
      "[' blood', ' bloods', ' blooding', ' blooded']\n",
      " blow\n",
      "[' blow', ' blows', ' blowing', ' blowed']\n",
      " bomb\n",
      "[' bomb', ' bombs', ' bombing', ' bombed']\n",
      " brown\n",
      "[' brown', ' browns', ' browning', ' browned']\n",
      " bruise\n",
      "[' bruise', ' bruises', ' bruising', ' bruised']\n",
      " burn\n",
      "[' burn', ' burns', ' burning', ' burned']\n",
      " call\n",
      "[' call', ' calls', ' calling', ' called']\n",
      " cancel\n",
      "[' cancel', ' cancels', ' cancelling', ' cancelled']\n",
      " careless\n",
      "[' careles', ' careless', ' carelessing', ' carelessed']\n",
      " caucasian\n",
      "[' caucasian', ' caucasians', ' caucasianing', ' caucasianed']\n",
      " charge\n",
      "[' charge', ' charges', ' charging', ' charged']\n",
      " claim\n",
      "[' claim', ' claims', ' claiming', ' claimed']\n",
      " compl\n",
      "[' compl', ' compls', ' compling', ' compled']\n",
      " confidential\n",
      "[' confidential', ' confidentials', ' confidentialing', ' confidentialed']\n",
      " consent\n",
      "[' consent', ' consents', ' consenting', ' consented']\n",
      " contact\n",
      "[' contact', ' contacts', ' contacting', ' contacted']\n",
      " cops\n",
      "[' cop', ' cops', ' copping', ' copped']\n",
      " court\n",
      "[' court', ' courts', ' courting', ' courted']\n",
      " criminal\n",
      "[' criminal', ' criminals', ' criminalling', ' criminalled']\n",
      " cruel\n",
      "[' cruel', ' cruels', ' crueling', ' crueled']\n",
      " custody\n",
      "[' custody', ' custodies', ' custodying', ' custodied']\n",
      " damage\n",
      "[' damage', ' damages', ' damaging', ' damaged']\n",
      " danger\n",
      "[' danger', ' dangers', ' dangerring', ' dangerred']\n",
      " dead\n",
      "[' dead', ' deads', ' deading', ' deaded']\n",
      " death\n",
      "[' death', ' deaths', ' deathing', ' deathed']\n",
      " delay\n",
      "[' delay', ' delays', ' delaying', ' delayed']\n",
      " demean\n",
      "[' demean', ' demeans', ' demeaning', ' demeaned']\n",
      " derelict\n",
      "[' derelict', ' derelicts', ' derelicting', ' derelicted']\n",
      " deserve\n",
      "[' deserve', ' deserves', ' deserving', ' deserved']\n",
      " destr\n",
      "[' destr', ' destrs', ' destring', ' destred']\n",
      " died\n",
      "[' die', ' dies', ' dieing', ' dieed']\n",
      " dign\n",
      "[' dign', ' digns', ' digning', ' digned']\n",
      " directive\n",
      "[' directive', ' directives', ' directiving', ' directived']\n",
      " dirt\n",
      "[' dirt', ' dirts', ' dirting', ' dirted']\n",
      " discrimin\n",
      "[' discrimin', ' discrimins', ' discriminning', ' discriminned']\n",
      " dismissive\n",
      "[' dismissive', ' dismissives', ' dismissiving', ' dismissived']\n",
      " electrocute\n",
      "[' electrocute', ' electrocutes', ' electrocuting', ' electrocuted']\n",
      " emergency\n",
      "[' emergency', ' emergencies', ' emergencying', ' emergencied']\n",
      " error\n",
      "[' error', ' errors', ' errorring', ' errorred']\n",
      " equal\n",
      "[' equal', ' equals', ' equaling', ' equaled']\n",
      " equity\n",
      "[' equity', ' equities', ' equitying', ' equitied']\n",
      " fail\n",
      "[' fail', ' fails', ' failing', ' failed']\n",
      " fault\n",
      "[' fault', ' faults', ' faulting', ' faulted']\n",
      " fight\n",
      "[' fight', ' fights', ' fighting', ' fighted']\n",
      " fired\n",
      "[' fire', ' fires', ' firing', ' fired']\n",
      " fix\n",
      "[' fix', ' fixes', ' fixing', ' fixed']\n",
      " flippan\n",
      "[' flippan', ' flippans', ' flippanning', ' flippanned']\n",
      " forgot\n",
      "[' forgot', ' forgots', ' forgotting', ' forgotted']\n",
      " fought\n",
      "[' fought', ' foughts', ' foughting', ' foughted']\n",
      " fraud\n",
      "[' fraud', ' frauds', ' frauding', ' frauded']\n",
      " gay\n",
      "[' gay', ' gays', ' gaying', ' gayed']\n",
      " gender\n",
      "[' gender', ' genders', ' genderring', ' genderred']\n",
      " grievance\n",
      "[' grievance', ' grievances', ' grievancing', ' grievanced']\n",
      " gun\n",
      "[' gun', ' guns', ' gunning', ' gunned']\n",
      " hack\n",
      "[' hack', ' hacks', ' hacking', ' hacked']\n",
      " harm\n",
      "[' harm', ' harms', ' harming', ' harmed']\n",
      " hate\n",
      "[' hate', ' hates', ' hating', ' hated']\n",
      " help\n",
      "[' help', ' helps', ' helping', ' helped']\n",
      " hipaa\n",
      "[' hipaa', ' hipaas', ' hipaaing', ' hipaaed']\n",
      " hippa\n",
      "[' hippa', ' hippas', ' hippaing', ' hippaed']\n",
      " hispanic\n",
      "[' hispanic', ' hispanices', ' hispanicking', ' hispanicked']\n",
      " horr\n",
      "[' horr', ' horrs', ' horring', ' horred']\n",
      " hot\n",
      "[' hot', ' hots', ' hotting', ' hotted']\n",
      " hurt\n",
      "[' hurt', ' hurts', ' hurting', ' hurted']\n",
      " ignore\n",
      "[' ignore', ' ignores', ' ignoring', ' ignored']\n",
      " illegal\n",
      "[' illegal', ' illegals', ' illegalling', ' illegalled']\n",
      " inadequate\n",
      "[' inadequate', ' inadequates', ' inadequating', ' inadequated']\n",
      " inappro\n",
      "[' inappro', ' inappros', ' inapproing', ' inapproed']\n",
      " inattent\n",
      "[' inattent', ' inattents', ' inattenting', ' inattented']\n",
      " incident\n",
      "[' incident', ' incidents', ' incidenting', ' incidented']\n",
      " incompetent\n",
      "[' incompetent', ' incompetents', ' incompetenting', ' incompetented']\n",
      " incorrect\n",
      "[' incorrect', ' incorrects', ' incorrecting', ' incorrected']\n",
      " infect\n",
      "[' infect', ' infects', ' infecting', ' infected']\n",
      " injur\n",
      "[' injur', ' injurs', ' injurring', ' injurred']\n",
      " insult\n",
      "[' insult', ' insults', ' insulting', ' insulted']\n",
      " irresponsibl\n",
      "[' irresponsibl', ' irresponsibls', ' irresponsibling', ' irresponsibled']\n",
      " jail\n",
      "[' jail', ' jails', ' jailing', ' jailed']\n",
      " jeopard\n",
      "[' jeopard', ' jeopards', ' jeoparding', ' jeoparded']\n",
      " kill\n",
      "[' kill', ' kills', ' killing', ' killed']\n",
      " lack\n",
      "[' lack', ' lacks', ' lacking', ' lacked']\n",
      " law\n",
      "[' law', ' laws', ' lawing', ' lawed']\n",
      " legal\n",
      "[' legal', ' legals', ' legalling', ' legalled']\n",
      " lesbian\n",
      "[' lesbian', ' lesbians', ' lesbianing', ' lesbianed']\n",
      " liable\n",
      "[' liable', ' liables', ' liabling', ' liabled']\n",
      " litigat\n",
      "[' litigat', ' litigats', ' litigatting', ' litigatted']\n",
      " malpractice\n",
      "[' malpractice', ' malpractices', ' malpracticing', ' malpracticed']\n",
      " massac\n",
      "[' massac', ' massacs', ' massaccing', ' massacced']\n",
      " man\n",
      "[' man', ' mans', ' manning', ' manned']\n",
      " mean\n",
      "[' mean', ' means', ' meaning', ' meaned']\n",
      " media\n",
      "[' media', ' medias', ' mediaing', ' mediaed']\n",
      " men\n",
      "[' men', ' mens', ' menning', ' menned']\n",
      " minorit\n",
      "[' minorit', ' minorits', ' minoritting', ' minoritted']\n",
      " mis\n",
      "[' mi', ' mis', ' miing', ' mied']\n",
      " MRSA\n",
      "[' mrsa', ' mrsas', ' mrsaing', ' mrsaed']\n",
      " murder\n",
      "[' murder', ' murders', ' murderring', ' murderred']\n",
      " negl\n",
      "[' negl', ' negls', ' negling', ' negled']\n",
      " nightmare\n",
      "[' nightmare', ' nightmares', ' nightmaring', ' nightmared']\n",
      " no\n",
      "[' no', ' nos', ' noing', ' noed']\n",
      " offen\n",
      "[' offen', ' offens', ' offenning', ' offenned']\n",
      " overdose\n",
      "[' overdose', ' overdoses', ' overdosing', ' overdosed']\n",
      " pain\n",
      "[' pain', ' pains', ' paining', ' pained']\n",
      " patroniz\n",
      "[' patroniz', ' patronizs', ' patronizzing', ' patronizzed']\n",
      " pistol\n",
      "[' pistol', ' pistols', ' pistolling', ' pistolled']\n",
      " police\n",
      "[' police', ' polices', ' policing', ' policed']\n",
      " priva\n",
      "[' priva', ' privas', ' privaing', ' privaed']\n",
      " problem\n",
      "[' problem', ' problems', ' problemming', ' problemmed']\n",
      " question\n",
      "[' question', ' questions', ' questioning', ' questioned']\n",
      " race\n",
      "[' race', ' races', ' racing', ' raced']\n",
      " racism\n",
      "[' racism', ' racisms', ' racisming', ' racismed']\n",
      " racist\n",
      "[' racist', ' racists', ' racisting', ' racisted']\n",
      " rape\n",
      "[' rape', ' rapes', ' raping', ' raped']\n",
      " reckless\n",
      "[' reckles', ' reckless', ' recklessing', ' recklessed']\n",
      " recover\n",
      "[' recover', ' recovers', ' recoverring', ' recoverred']\n",
      " regret\n",
      "[' regret', ' regrets', ' regretting', ' regretted']\n",
      " respect\n",
      "[' respect', ' respects', ' respecting', ' respected']\n",
      " ridiculous\n",
      "[' ridiculou', ' ridiculous', ' ridiculouing', ' ridiculoued']\n",
      " rifle\n",
      "[' rifle', ' rifles', ' rifling', ' rifled']\n",
      " rights\n",
      "[' right', ' rights', ' righting', ' righted']\n",
      " risk\n",
      "[' risk', ' risks', ' risking', ' risked']\n",
      " rude\n",
      "[' rude', ' rudes', ' ruding', ' ruded']\n",
      " ruin\n",
      "[' ruin', ' ruins', ' ruining', ' ruined']\n",
      " safe\n",
      "[' safe', ' safes', ' safing', ' safed']\n",
      " secur\n",
      "[' secur', ' securs', ' securring', ' securred']\n",
      " sepsis\n",
      "[' sepsi', ' sepsis', ' sepsiing', ' sepsied']\n",
      " severe\n",
      "[' severe', ' severes', ' severing', ' severed']\n",
      " sexual\n",
      "[' sexual', ' sexuals', ' sexualing', ' sexualed']\n",
      " shock\n",
      "[' shock', ' shocks', ' shocking', ' shocked']\n",
      " shoot\n",
      "[' shoot', ' shoots', ' shooting', ' shooted']\n",
      " slay\n",
      "[' slay', ' slays', ' slaying', ' slayed']\n",
      " sorry\n",
      "[' sorry', ' sorries', ' sorrying', ' sorried']\n",
      " stab\n",
      "[' stab', ' stabs', ' stabbing', ' stabbed']\n",
      " steal\n",
      "[' steal', ' steals', ' stealing', ' stealed']\n",
      " stole\n",
      "[' stole', ' stoles', ' stoling', ' stoled']\n",
      " stop\n",
      "[' stop', ' stops', ' stopping', ' stopped']\n",
      " sue\n",
      "[' sue', ' sues', ' sueing', ' sueed']\n",
      " suffer\n",
      "[' suffer', ' suffers', ' sufferring', ' sufferred']\n",
      " suicid\n",
      "[' suicid', ' suicids', ' suicidding', ' suicidded']\n",
      " suit\n",
      "[' suit', ' suits', ' suiting', ' suited']\n",
      " terr\n",
      "[' terr', ' terrs', ' terring', ' terred']\n",
      " threat\n",
      "[' threat', ' threats', ' threating', ' threated']\n",
      " trag\n",
      "[' trag', ' trags', ' tragging', ' tragged']\n",
      " transgr\n",
      "[' transgr', ' transgrs', ' transgring', ' transgred']\n",
      " trauma\n",
      "[' trauma', ' traumas', ' traumaing', ' traumaed']\n",
      " travesty\n",
      "[' travesty', ' travesties', ' travestying', ' travestied']\n",
      " trouble\n",
      "[' trouble', ' troubles', ' troubling', ' troubled']\n",
      " un\n",
      "[' un', ' uns', ' unning', ' unned']\n",
      " upset\n",
      "[' upset', ' upsets', ' upsetting', ' upsetted']\n",
      " viol\n",
      "[' viol', ' viols', ' violing', ' violed']\n",
      " waste\n",
      "[' waste', ' wastes', ' wasting', ' wasted']\n",
      " weapon\n",
      "[' weapon', ' weapons', ' weaponning', ' weaponned']\n",
      " white\n",
      "[' white', ' whites', ' whiting', ' whited']\n",
      " woman\n",
      "[' woman', ' womans', ' womanning', ' womanned']\n",
      " women\n",
      "[' women', ' womens', ' womenning', ' womenned']\n",
      " wound\n",
      "[' wound', ' wounds', ' wounding', ' wounded']\n",
      " wrath\n",
      "[' wrath', ' wraths', ' wrathing', ' wrathed']\n",
      " wrong\n",
      "[' wrong', ' wrongs', ' wronging', ' wronged']\n",
      " 414\n",
      "[' 414', ' 414s', ' 414ing', ' 414ed']\n",
      " 262\n",
      "[' 262', ' 262s', ' 262ing', ' 262ed']\n",
      " 0\n",
      "[' 0', ' 0s', ' 0ing', ' 0ed']\n",
      " -1\n",
      "[' -1', ' -1s', ' -1ing', ' -1ed']\n",
      " -2\n",
      "[' -2', ' -2s', ' -2ing', ' -2ed']\n",
      " -3\n",
      "[' -3', ' -3s', ' -3ing', ' -3ed']\n",
      " -4\n",
      "[' -4', ' -4s', ' -4ing', ' -4ed']\n",
      " -5\n",
      "[' -5', ' -5s', ' -5ing', ' -5ed']\n",
      " -6\n",
      "[' -6', ' -6s', ' -6ing', ' -6ed']\n",
      " -7\n",
      "[' -7', ' -7s', ' -7ing', ' -7ed']\n",
      " -8\n",
      "[' -8', ' -8s', ' -8ing', ' -8ed']\n",
      " -9\n",
      "[' -9', ' -9s', ' -9ing', ' -9ed']\n",
      " 0\n",
      "[' 0', ' 0s', ' 0ing', ' 0ed']\n",
      " 0.1\n",
      "[' 0.1', ' 0.1s', ' 0.1ing', ' 0.1ed']\n",
      " 0.2\n",
      "[' 0.2', ' 0.2s', ' 0.2ing', ' 0.2ed']\n",
      " 0.3\n",
      "[' 0.3', ' 0.3s', ' 0.3ing', ' 0.3ed']\n",
      " 0.4\n",
      "[' 0.4', ' 0.4s', ' 0.4ing', ' 0.4ed']\n",
      " 0.5\n",
      "[' 0.5', ' 0.5s', ' 0.5ing', ' 0.5ed']\n",
      " 0.6\n",
      "[' 0.6', ' 0.6s', ' 0.6ing', ' 0.6ed']\n",
      " 0.7\n",
      "[' 0.7', ' 0.7s', ' 0.7ing', ' 0.7ed']\n",
      " 0.8\n",
      "[' 0.8', ' 0.8s', ' 0.8ing', ' 0.8ed']\n",
      " 0.9\n",
      "[' 0.9', ' 0.9s', ' 0.9ing', ' 0.9ed']\n",
      " @\n",
      "[' @', ' @s', ' @ing', ' @ed']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"./Data/keywords.txt\", \"r\")\n",
    "file_data = file.read()\n",
    "\n",
    "word_nlp = nlp(file_data)\n",
    "\n",
    "for token in word_nlp:\n",
    "    if token.is_punct: continue\n",
    "    #print(token, token.lemma_)\n",
    " \n",
    "# Special Feature : to get all possible lemmas for each word in the sentence\n",
    "#all_lemmas_for_each_word = [lexeme(wd) for wd in file_data.split(',')]\n",
    "#print(all_lemmas_for_each_word)\n",
    "\n",
    "words = file_data.split(',')\n",
    "\n",
    "for word in words:\n",
    "    word_clean = word.replace('\\\"', '')\n",
    "    all_lemmas_for_each_word = lexeme(word_clean)\n",
    "    print(word_clean)\n",
    "    print(all_lemmas_for_each_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.quora.com/NLP-whats-the-best-method-to-detect-negated-contexts-in-text\n",
    "#https://spacy.io/universe/project/negspacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting negspacy\n",
      "  Downloading negspacy-1.0.3.tar.gz (11 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.0.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from negspacy) (3.4.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (0.10.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (4.64.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (1.22.4)\n",
      "Requirement already satisfied: jinja2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (0.10.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (3.3.0)\n",
      "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (0.7.0)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (8.1.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (3.0.8)\n",
      "Requirement already satisfied: setuptools in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (65.5.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (1.0.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (3.0.10)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (2.0.7)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (1.10.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (21.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from spacy<4.0.0,>=3.0.1->negspacy) (2.4.5)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from packaging>=20.0->spacy<4.0.0,>=3.0.1->negspacy) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<4.0.0,>=3.0.1->negspacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<4.0.0,>=3.0.1->negspacy) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.1->negspacy) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.1->negspacy) (2022.6.15)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.1->negspacy) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.0.1->negspacy) (1.26.13)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.1->negspacy) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy<4.0.0,>=3.0.1->negspacy) (0.7.9)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from typer<0.8.0,>=0.3.0->spacy<4.0.0,>=3.0.1->negspacy) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from jinja2->spacy<4.0.0,>=3.0.1->negspacy) (2.1.1)\n",
      "Building wheels for collected packages: negspacy\n",
      "  Building wheel for negspacy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for negspacy: filename=negspacy-1.0.3-py3-none-any.whl size=10417 sha256=b40663ca82d49bd7146f61cc554caec47786625d08f25bd93ca7f12c19fb3dc4\n",
      "  Stored in directory: /Users/sajjadislam/Library/Caches/pip/wheels/ec/4b/5b/ae823d4b232c1342724ec93edab9f3dca6403679d93e0daa25\n",
      "Successfully built negspacy\n",
      "Installing collected packages: negspacy\n",
      "Successfully installed negspacy-1.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install negspacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steve Jobs True\n",
      "Apple False\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from negspacy.negation import Negex\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"negex\", config={\"ent_types\":[\"PERSON\",\"ORG\"]})\n",
    "\n",
    "doc = nlp(\"She does not like Steve Jobs but likes Apple products.\")\n",
    "for e in doc.ents:\n",
    "    print(e.text, e._.negex)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "US phone number search.\n",
    "\n",
    "#https://stackoverflow.com/questions/3868753/find-usa-phone-numbers-in-python-script/28864077#28864077\n",
    "\n",
    "#https://softhints.com/regex-phone-number-find-validation-python/\n",
    "\n",
    "#https://www.abstractapi.com/guides/phone-number-python-regex\n",
    "\n",
    "https://stackoverflow.com/questions/16699007/regular-expression-to-match-standard-10-digit-phone-number?fbclid=IwAR3fXKgZXuwLC1xyu_UIvlyIrp6jqvWQE_XccUyHJ_jWlNBt3ydaQl197UE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phone_number ::  4172334455\n",
      "['4172334455']\n",
      "['4172334455']\n",
      "phone_number ::  +14172334455\n",
      "['1417233445']\n",
      "['+14172334455']\n",
      "phone_number ::  2334455\n",
      "['2334455']\n",
      "[]\n",
      "phone_number ::  This is my phone no. please call 4172334455\n",
      "['4172334455']\n",
      "['4172334455']\n",
      "phone_number ::  4172334455 This is my phone no.\n",
      "['4172334455']\n",
      "[]\n",
      "phone_number ::  This is my phone no. please call4172334455\n",
      "['4172334455']\n",
      "['4172334455']\n",
      "phone_number ::  please call (417) 123 9900\n",
      "['(417) 123 9900']\n",
      "['(417) 123 9900']\n",
      "phone_number ::  please call 414-123-3344\n",
      "['414-123-3344']\n",
      "['414-123-3344']\n",
      "phone_number ::  please call 414.233.4433\n",
      "['414.233.4433']\n",
      "['414.233.4433']\n",
      "phone_number ::  please call 414 123 3344\n",
      "['414 123 3344']\n",
      "['414 123 3344']\n",
      "phone_number ::  1234567890111\n",
      "['1234567890']\n",
      "['234567890111']\n",
      "phone_number ::  +918477812345\n",
      "['9184778123']\n",
      "['+918477812345']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern_phone = '(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})'\n",
    "pattern_phone_2 = \"[\\+]?[(]?[0-9]{3}[)]?[-\\s\\.]?[0-9]{3}[-\\s\\.]?[0-9]{4,6}$\"\n",
    "phone_numbers = ['4172334455', '+14172334455', '2334455', 'This is my phone no. please call 4172334455', '4172334455 This is my phone no.', \n",
    "'This is my phone no. please call4172334455', 'please call (417) 123 9900', 'please call 414-123-3344', 'please call 414.233.4433', 'please call 414 123 3344', '1234567890111', '+918477812345']\n",
    "for phone_number in phone_numbers:\n",
    "    print('phone_number :: ', phone_number)\n",
    "    match1 = re.findall(pattern_phone, phone_number)\n",
    "    match2 = re.findall(pattern_phone_2, phone_number)\n",
    "    print(match1)\n",
    "    print(match2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4172334455']\n",
      "['+141723344']\n",
      "['2334455']\n",
      "['4172334455']\n",
      "['4172334455']\n",
      "['4172334455']\n",
      "['(417) 123 9900']\n",
      "['414-123-3344']\n",
      "['414.233.4433']\n",
      "['414 123 3344']\n",
      "['12345678901']\n",
      "['8477812345']\n",
      "['(123) 456-7890']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "phone_regex = '((?:\\+\\d{2}[-\\.\\s]??|\\d{4}[-\\.\\s]??)?(?:\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4}))'\n",
    "\n",
    "phone_numbers = ['4172334455', '+14172334455', '2334455', 'This is my phone no. please call 4172334455', '4172334455 This is my phone no.', \n",
    "'This is my phone no. please call4172334455', 'please call (417) 123 9900', 'please call 414-123-3344', 'please call 414.233.4433', 'please call 414 123 3344', '1234567890111', \n",
    "'+91–8477812345', '(123) 456-7890']\n",
    "for phone_number in phone_numbers:\n",
    "    match = re.findall(phone_regex, phone_number)\n",
    "    print(match)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.regextester.com/94779"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('', '233')]\n",
      "[('+1', '233')]\n",
      "[]\n",
      "[('', '233')]\n",
      "[('', '233')]\n",
      "[('', '233')]\n",
      "[]\n",
      "[('', '123-')]\n",
      "[('', '233.')]\n",
      "[]\n",
      "[('12', '678')]\n",
      "[('', '781')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern_phone = \"([+]?\\d{1,2}[-\\.\\s]?)?(\\d{3}[-\\.]?){2}\\d{4}\"\n",
    "phone_numbers = ['4172334455', '+14172334455', '2334455', 'This is my phone no. please call 4172334455', '4172334455 This is my phone no.', \n",
    "'This is my phone no. please call4172334455', 'please call (417) 123 9900', 'please call 414-123-3344', 'please call 414.233.4433', 'please call 414 123 3344', '1234567890111', '+91–8477812345']\n",
    "for phone_number in phone_numbers:\n",
    "    match = re.findall(pattern_phone, phone_number)\n",
    "    print(match)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ihateregex.io/expr/phone/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4172334455\n",
      "['4172334455']\n",
      "+14172334455\n",
      "['+14172334455']\n",
      "2334455\n",
      "[]\n",
      "This is my phone no. please call 4172334455\n",
      "['4172334455']\n",
      "4172334455 This is my phone no.\n",
      "[]\n",
      "Phone 4172334455\n",
      "['4172334455']\n",
      "This is my phone no. please call4172334455\n",
      "['4172334455']\n",
      "please call (417) 123 9900\n",
      "['(417) 123 9900']\n",
      "please call 414-123-3344\n",
      "['414-123-3344']\n",
      "please call 414.233.4433\n",
      "['414.233.4433']\n",
      "please call 414 123 3344\n",
      "['414 123 3344']\n",
      "1234567890111\n",
      "['234567890111']\n",
      "+918477812345\n",
      "['+918477812345']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern_phone = \"[\\+]?[(]?[0-9]{3}[)]?[-\\s\\.]?[0-9]{3}[-\\s\\.]?[0-9]{4,6}$\"\n",
    "phone_numbers = ['4172334455', '+14172334455', '2334455', 'This is my phone no. please call 4172334455', '4172334455 This is my phone no.', 'Phone 4172334455', \n",
    "'This is my phone no. please call4172334455', 'please call (417) 123 9900', 'please call 414-123-3344', 'please call 414.233.4433', 'please call 414 123 3344', '1234567890111', '+918477812345']\n",
    "for phone_number in phone_numbers:\n",
    "    print(phone_number)\n",
    "    match = re.findall(pattern_phone, phone_number)\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "pattern_phone = '(\\d{3}[-\\.\\s]??\\d{3}[-\\.\\s]??\\d{4}|\\(\\d{3}\\)\\s*\\d{3}[-\\.\\s]??\\d{4}|\\d{3}[-\\.\\s]??\\d{4})'\n",
    "phone_numbers = ['This is my phone no. please call 4172334455', \n",
    "'4172334455 This is my phone no.', \n",
    "'This is my phone no. please call4172334455', \n",
    "'please call (417) 123 9900', \n",
    "'please call 414-123-3344', \n",
    "'please call 414.233.4433', \n",
    "'please call 414 123 3344', \n",
    "'please call at +91–8477812345']\n",
    "for phone_number in phone_numbers:\n",
    "    match = re.findall(pattern_phone, phone_number)\n",
    "    print(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Email search\n",
    "\n",
    "#https://automatetheboringstuff.com/chapter7/\n",
    "\n",
    "#https://www.folkstalk.com/2022/10/finding-email-id-from-string-python-with-code-examples.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "john.doe@somecompany.co.uk\n",
      "jane_doe124@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "my_str = \"Hi my name is John and email address is john.doe@somecompany.co.uk and my friend's email is jane_doe124@gmail.com and another email is hh@mail\"\n",
    "pattern_email = \"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\"\n",
    "emails = re.findall(pattern_email, my_str)\n",
    "\n",
    "for mail in emails:\n",
    "    print(mail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/74175424/is-spacy-lemmatization-not-working-properly-or-does-it-not-lemmatize-all-words-e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argumentum\n",
      "argumentum\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('argumentum')\n",
    "for token in doc:\n",
    "    print(token.lemma_)\n",
    "    print(token.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argument\n"
     ]
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "word_root = ps.stem('argument')\n",
    "print(word_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/67342461/how-to-generate-all-derived-terms-out-of-a-root-or-lemma-word-in-english-using-s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$  --  symbol, currency\n",
      "''  --  closing quotation mark\n",
      ",  --  punctuation mark, comma\n",
      "-LRB-  --  left round bracket\n",
      "-RRB-  --  right round bracket\n",
      ".  --  punctuation mark, sentence closer\n",
      ":  --  punctuation mark, colon or ellipsis\n",
      "ADD  --  email\n",
      "AFX  --  affix\n",
      "CC  --  conjunction, coordinating\n",
      "CD  --  cardinal number\n",
      "DT  --  determiner\n",
      "EX  --  existential there\n",
      "FW  --  foreign word\n",
      "HYPH  --  punctuation mark, hyphen\n",
      "IN  --  conjunction, subordinating or preposition\n",
      "JJ  --  adjective (English), other noun-modifier (Chinese)\n",
      "JJR  --  adjective, comparative\n",
      "JJS  --  adjective, superlative\n",
      "LS  --  list item marker\n",
      "MD  --  verb, modal auxiliary\n",
      "NFP  --  superfluous punctuation\n",
      "NN  --  noun, singular or mass\n",
      "NNP  --  noun, proper singular\n",
      "NNPS  --  noun, proper plural\n",
      "NNS  --  noun, plural\n",
      "PDT  --  predeterminer\n",
      "POS  --  possessive ending\n",
      "PRP  --  pronoun, personal\n",
      "PRP$  --  pronoun, possessive\n",
      "RB  --  adverb\n",
      "RBR  --  adverb, comparative\n",
      "RBS  --  adverb, superlative\n",
      "RP  --  adverb, particle\n",
      "SYM  --  symbol\n",
      "TO  --  infinitival \"to\"\n",
      "UH  --  interjection\n",
      "VB  --  verb, base form\n",
      "VBD  --  verb, past tense\n",
      "VBG  --  verb, gerund or present participle\n",
      "VBN  --  verb, past participle\n",
      "VBP  --  verb, non-3rd person singular present\n",
      "VBZ  --  verb, 3rd person singular present\n",
      "WDT  --  wh-determiner\n",
      "WP  --  wh-pronoun, personal\n",
      "WP$  --  wh-pronoun, possessive\n",
      "WRB  --  wh-adverb\n",
      "XX  --  unknown\n",
      "_SP  --  whitespace\n",
      "``  --  opening quotation mark\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "for label in nlp.get_pipe(\"tagger\").labels:\n",
    "    print(label, \" -- \", spacy.explain(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argue - argue - None - None - None - None - arguing - argued - argued\n",
      "argument - None - argument - None - None - None - None - None - None\n",
      "abuse - abuse - abuse - None - None - None - abusing - abused - abused\n",
      "abusable - None - None - None - None - None - None - None - None\n",
      "injure - injure - None - None - None - None - injuring - injured - injured\n",
      "injury - None - injury - None - None - None - None - None - None\n",
      "arguable - None - None - arguable - arguable - None - None - None - None\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import pyinflect\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "sentence = \"argue argument abuse abusable injure injury arguable\"\n",
    "doc = nlp(sentence)\n",
    "for token in doc:\n",
    "    base = token._.inflect(\"VB\")\n",
    "    noun = token._.inflect(\"NN\")\n",
    "    adverb = token._.inflect(\"RB\")\n",
    "    adjective = token._.inflect(\"JJ\")\n",
    "    possessive = token._.inflect(\"POS\")\n",
    "    gerund = token._.inflect(\"VBG\")\n",
    "    past_tense = token._.inflect(\"VBD\")\n",
    "    past_participle = token._.inflect(\"VBN\")\n",
    "    print(token.text, \"-\", base, \"-\", noun, \"-\", adverb, \"-\", adjective, \"-\", possessive, \"-\", gerund, \"-\", past_tense, \"-\", past_participle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting word_forms\n",
      "  Downloading word_forms-2.1.0-py3-none-any.whl (166 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.3/166.3 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting inflect==4.1.0\n",
      "  Downloading inflect-4.1.0-py3-none-any.whl (31 kB)\n",
      "Requirement already satisfied: nltk>=3.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from word_forms) (3.7)\n",
      "Requirement already satisfied: click in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk>=3.3->word_forms) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk>=3.3->word_forms) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk>=3.3->word_forms) (4.64.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/sajjadislam/opt/anaconda3/envs/py_venv_complain/lib/python3.9/site-packages (from nltk>=3.3->word_forms) (2022.3.15)\n",
      "Installing collected packages: inflect, word_forms\n",
      "  Attempting uninstall: inflect\n",
      "    Found existing installation: inflect 6.0.2\n",
      "    Uninstalling inflect-6.0.2:\n",
      "      Successfully uninstalled inflect-6.0.2\n",
      "Successfully installed inflect-4.1.0 word_forms-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U word_forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.org/project/word-forms/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n': {'confidences', 'confidants', 'confidentialities', 'confidant', 'confidentiality', 'confidence'}, 'a': {'confident', 'confidential'}, 'v': {'confides', 'confided', 'confide', 'confiding'}, 'r': {'confidently', 'confidentially'}}\n",
      "private\n",
      "private\n",
      "privates\n",
      "private\n",
      "privatenesses\n",
      "privateness\n",
      "privateness\n",
      "privateness\n"
     ]
    }
   ],
   "source": [
    "from word_forms.word_forms import get_word_forms\n",
    "print(get_word_forms(\"confidential\"))\n",
    "\n",
    "for word in get_word_forms(\"private\")['n']:\n",
    "    print(word)\n",
    "    doc = nlp(word)\n",
    "    for token in doc:\n",
    "        print(token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lemmatized vocab list ::  ['accidental', 'accident', 'accidentally', 'adversity', 'adversitie', 'adverse', 'adversely', 'age', 'aged', 'agitator', 'agitative', 'agitate', 'anger', 'angrinesse', 'angriness', 'angry', 'angrily', 'assaulter', 'assault', 'assaultive', 'attack', 'attacker', 'attorney', 'attorneyship', 'awfulnesse', 'awfulness', 'awful', 'awfully', 'badness', 'bad', 'badly', 'battery', 'blacknesse', 'black', 'blackness', 'blackmail', 'blackmailer', 'blame', 'blameworthiness', 'blameable', 'blamable', 'blameworthy', 'blatancy', 'blatant', 'blatantly', 'bleeder', 'bleeding', 'bleed', 'bloodiness', 'blood', 'bloody', 'bloodie', 'bloodily', 'blow', 'blower', 'blowing', 'blowy', 'bomber', 'bomblet', 'bombing', 'bomb', 'brown', 'brownness', 'brownnesse', 'bruise', 'bruiser', 'burn', 'burner', 'burnable', 'call', 'caller', 'calling', 'callable', 'cancel', 'cancellation', 'carelessness', 'careless', 'carelessly', 'charge', 'charger', 'claim', 'claimant', 'confidence', 'confidant', 'confidentiality', 'confident', 'confidential', 'confide', 'confidently', 'confidentially', 'consent', 'consentaneous', 'contact', 'cop', 'court', 'courting', 'courtliness', 'courtly', 'incrimination', 'criminalness', 'criminal', 'crime', 'criminality', 'incriminatory', 'criminatory', 'criminative', 'criminalize', 'incriminate', 'criminate', 'criminalise', 'criminally', 'cruelness', 'cruel', 'cruelly', 'custody', 'custodianship', 'custodian', 'custodial', 'damage', 'dangerousness', 'danger', 'dangerous', 'dangerously', 'dead', 'deadness', 'deadnesse', 'deadly', 'die', 'dying', 'death', 'dice', 'deathly', 'delay', 'demean', 'demeaning', 'derelict', 'deserve', 'director', 'directivity', 'directive', 'directness', 'directorship', 'directiveness', 'direct', 'directly', 'dirt', 'dirtying', 'dirtiness', 'dirty', 'dirtinesse', 'dirtie', 'dirtily', 'dismission', 'dismissal', 'dismissible', 'dismissive', 'dismiss', 'electrocution', 'electrocute', 'emergence', 'emersion', 'emergency', 'emergent', 'emerge', 'error', 'errancy', 'errant', 'err', 'equating', 'equator', 'equal', 'equatorial', 'equation', 'equality', 'equate', 'equally', 'equity', 'failure', 'fail', 'failing', 'fault', 'faultinesse', 'faultiness', 'faulty', 'faultily', 'fight', 'fighting', 'fighter', 'fieriness', 'firing', 'fire', 'fiery', 'fierily', 'fixer', 'fix', 'fixture', 'fixing', 'forget', 'fraud', 'gay', 'gayness', 'gaily', 'gender', 'grievance', 'gunner', 'gun', 'hack', 'hacker', 'harm', 'hater', 'hate', 'helping', 'helper', 'help', 'hotness', 'hot', 'hotly', 'hurt', 'hurting', 'ignorantness', 'ignorance', 'ignorant', 'ignore', 'ignorantly', 'illegality', 'illegal', 'illegally', 'inadequateness', 'inadequate', 'inadequately', 'incident', 'incidence', 'incompetent', 'incompetency', 'incompetence', 'incompetently', 'incorrectness', 'incorrect', 'incorrectly', 'infection', 'infective', 'infectious', 'infect', 'infectiously', 'insult', 'jail', 'jailor', 'jailer', 'kill', 'killer', 'killing', 'killable', 'killingly', 'lack', 'lawyer', 'law', 'legality', 'legal', 'legally', 'lesbian', 'liability', 'liable', 'malpractice', 'manliness', 'man', 'manly', 'mean', 'meaning', 'meanness', 'meanly', 'medium', 'medial', 'medially', 'murder', 'murderer', 'murderousness', 'murderousnesse', 'murderous', 'murderously', 'nightmare', 'noe', 'no', 'overdose', 'pain', 'pistol', 'pistoleer', 'police', 'problem', 'problematical', 'problematic', 'problematically', 'questioner', 'questioning', 'question', 'questioningly', 'racer', 'racinesse', 'race', 'racing', 'raciness', 'racy', 'racial', 'racily', 'racially', 'racism', 'racist', 'rape', 'raper', 'recklessness', 'reckless', 'recklessly', 'recoverer', 'recovery', 'recover', 'regret', 'respect', 'respecter', 'ridicule', 'ridiculousness', 'ridiculer', 'ridiculous', 'ridiculously', 'rifle', 'rightnesse', 'right', 'rightness', 'riskiness', 'risk', 'risky', 'riskily', 'rudeness', 'rudenesse', 'rude', 'rudely', 'ruination', 'ruin', 'ruiner', 'ruining', 'ruinous', 'ruinously', 'safenesse', 'safe', 'safeness', 'sepse', 'sepsis', 'septic', 'severeness', 'severenesse', 'severity', 'severitie', 'severe', 'severely', 'sexiness', 'sex', 'sexuality', 'sexual', 'sexy', 'sexually', 'shock', 'shocker', 'shocking', 'shooting', 'shoot', 'shooter', 'slayer', 'slaying', 'slay', 'slew', 'sorriness', 'sorry', 'stab', 'stabber', 'stealer', 'steal', 'stealing', 'stole', 'stopper', 'stop', 'stoppage', 'suer', 'suit', 'sue', 'suffer', 'sufferance', 'suffering', 'sufferer', 'threat', 'trauma', 'traumatic', 'traumatizing', 'traumatize', 'traumatise', 'travesty', 'trouble', 'troublous', 'troubling', 'upsetter', 'upset', 'upsetting', 'waster', 'waste', 'wasting', 'wastage', 'weapon', 'weaponize', 'white', 'whiteness', 'womanliness', 'womanlinesse', 'womaniser', 'womanizer', 'womanhood', 'woman', 'womanly', 'womanize', 'womanise', 'winder', 'wound', 'windiness', 'wind', 'wounding', 'windy', 'windily', 'wrath', 'wrong', 'wrongness', 'wrongly', 'abuser', 'abuse', 'abusive', 'abusively', 'agony', 'agonist', 'agon', 'agonistic', 'agonal', 'agonize', 'agonise', 'apology', 'apologist', 'apologetic', 'apologize', 'apologise', 'apologetically', 'arguer', 'argument', 'argumentation', 'argumentative', 'arguable', 'argue', 'arguably', 'argumentatively', 'complainant', 'complaint', 'complainer', 'complain', 'destructibility', 'destructibilitie', 'destructiveness', 'destroyer', 'destruction', 'destructible', 'destructive', 'destroy', 'destructively', 'discrimination', 'discriminator', 'discriminate', 'discriminatory', 'discriminative', 'dignity', 'dignifie', 'dignify', 'indignity', 'flippancy', 'flippant', 'flippantly', 'horror', 'horrify', 'horrifie', 'horrible', 'horribly', 'inappropriateness', 'inappropriate', 'inappropriately', 'injuriousness', 'injury', 'injurious', 'injure', 'injuriously', 'irresponsibility', 'irresponsibleness', 'irresponsible', 'irresponsibly', 'litigiousness', 'litigation', 'litigator', 'litigant', 'litigious', 'litigate', 'inattentiveness', 'inattentivenesse', 'inattentive', 'inattentively', 'inattention', 'massacre', 'minority', 'minor', 'negligence', 'neglect', 'neglecter', 'negligent', 'negligently', 'offensivenesse', 'offense', 'offender', 'offensive', 'offensiveness', 'offence', 'offend', 'offensively', 'patron', 'patronize', 'patronise', 'private', 'privateness', 'privately', 'privacy', 'secureness', 'security', 'securer', 'secure', 'securely', 'terribleness', 'terrible', 'terribly', 'tragedy', 'tragic', 'tragical', 'tragically', 'suicide', 'suicidal', 'transgressor', 'transgression', 'transgress', 'transgresse', 'transgressing', 'violence', 'violent', 'violently', 'mis', 'mi']\n"
     ]
    }
   ],
   "source": [
    "FILE_PATH_VOCAB = \"./Data/keywords.txt\"\n",
    "def get_vocab_list():\n",
    "    vocab_list = []\n",
    "    file_vocab = open(FILE_PATH_VOCAB, \"r\")\n",
    "    file_vocab_data = file_vocab.read()\n",
    "    words = file_vocab_data.split(',')\n",
    "    for word in words:\n",
    "        word = word.strip()\n",
    "        word_forms_dict = get_word_forms(word)\n",
    "        word_forms_lists = list(word_forms_dict.values())\n",
    "     \n",
    "        for word_form_list in word_forms_lists:\n",
    "            for word_form in word_form_list:\n",
    "                doc = nlp(word_form)\n",
    "                for token in doc:\n",
    "                    vocab_lemma = token.lemma_\n",
    "                    if vocab_lemma not in vocab_list: \n",
    "                        vocab_list.append(vocab_lemma)\n",
    "\n",
    "    return vocab_list\n",
    "    \n",
    "vocab_list = get_vocab_list()\n",
    "print('lemmatized vocab list :: ', vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident\n",
      "adverse\n",
      "african\n",
      "age\n",
      "agitate\n",
      "american\n",
      "anger\n",
      "angry\n",
      "assault\n",
      "attack\n",
      "attorney\n",
      "awful\n",
      "bad\n",
      "battery\n",
      "black\n",
      "blackmail\n",
      "blame\n",
      "blatant\n",
      "bleed\n",
      "blood\n",
      "blow\n",
      "bomb\n",
      "brown\n",
      "bruise\n",
      "burn\n",
      "call\n",
      "cancel\n",
      "careless\n",
      "caucasian\n",
      "charge\n",
      "claim\n",
      "confidential\n",
      "consent\n",
      "contact\n",
      "cop\n",
      "court\n",
      "criminal\n",
      "cruel\n",
      "custody\n",
      "damage\n",
      "danger\n",
      "dead\n",
      "death\n",
      "delay\n",
      "demean\n",
      "derelict\n",
      "deserve\n",
      "die\n",
      "directive\n",
      "dirt\n",
      "dismissive\n",
      "electrocute\n",
      "emergency\n",
      "error\n",
      "equal\n",
      "equity\n",
      "fail\n",
      "fault\n",
      "fight\n",
      "fire\n",
      "fix\n",
      "forget\n",
      "fight\n",
      "fraud\n",
      "gay\n",
      "gender\n",
      "grievance\n",
      "gun\n",
      "hack\n",
      "harm\n",
      "hate\n",
      "help\n",
      "hispanic\n",
      "hot\n",
      "hurt\n",
      "ignore\n",
      "illegal\n",
      "inadequate\n",
      "incident\n",
      "incompetent\n",
      "incorrect\n",
      "infect\n",
      "insult\n",
      "jail\n",
      "jeopard\n",
      "kill\n",
      "lack\n",
      "law\n",
      "legal\n",
      "lesbian\n",
      "liable\n",
      "malpractice\n",
      "man\n",
      "mean\n",
      "media\n",
      "murder\n",
      "nightmare\n",
      "no\n",
      "overdose\n",
      "pain\n",
      "pistol\n",
      "police\n",
      "problem\n",
      "question\n",
      "race\n",
      "racism\n",
      "racist\n",
      "rape\n",
      "reckless\n",
      "recover\n",
      "regret\n",
      "respect\n",
      "ridiculous\n",
      "rifle\n",
      "rights\n",
      "risk\n",
      "rude\n",
      "ruin\n",
      "safe\n",
      "sepsis\n",
      "severe\n",
      "sexual\n",
      "shock\n",
      "shoot\n",
      "slay\n",
      "sorry\n",
      "stab\n",
      "steal\n",
      "stole\n",
      "stop\n",
      "sue\n",
      "suffer\n",
      "suit\n",
      "threat\n",
      "trauma\n",
      "travesty\n",
      "trouble\n",
      "upset\n",
      "waste\n",
      "weapon\n",
      "white\n",
      "woman\n",
      "wound\n",
      "wrath\n",
      "wrong\n",
      "abuse\n",
      "agony\n",
      "apology\n",
      "argue\n",
      "complain\n",
      "destroy\n",
      "discrimination\n",
      "dignity\n",
      "indignity\n",
      "flippant\n",
      "horror\n",
      "horrible\n",
      "inappropriate\n",
      "injure\n",
      "irresponsible\n",
      "litigate\n",
      "inattentive\n",
      "inattention\n",
      "massacre\n",
      "minority\n",
      "neglect\n",
      "offend\n",
      "patronize\n",
      "private\n",
      "privacy\n",
      "secure\n",
      "terrible\n",
      "tragic\n",
      "suicide\n",
      "transgress\n",
      "violent\n",
      "un\n",
      "mis\n",
      "MRSA\n",
      "hipaa\n",
      "hippa\n"
     ]
    }
   ],
   "source": [
    "file = open(\"./Data/keywords.txt\", \"r\")\n",
    "file_data = file.read()\n",
    "\n",
    "words = file_data.split(',')\n",
    "\n",
    "for word in words:\n",
    "    print(word.strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('py_venv_complain')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68c3b94dfdbec0734c4e91bb2deb554e5e54ee6de2b3cc8d3baf45aa3750ddec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

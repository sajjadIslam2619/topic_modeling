{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5b5QQIQl7dz",
        "outputId": "32d65c13-f5cb-4d9e-c48b-c9fc1bd0c754"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8R4IfSWpo5d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEf2Pedoomux"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./Data/patient_review_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2TtHMHDI0Bi"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"./Data/test_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVNAqyzHKgsX",
        "outputId": "19eca1f0-4a9d-4615-b5f4-775d3dfdb2e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0      15 Highly Important Questions About Adulthood,...\n",
              "1      250 Nuns Just Cycled All The Way From Kathmand...\n",
              "2      Australian comedians \"could have been shot\" du...\n",
              "3      Lycos launches screensaver to increase spammer...\n",
              "4      Fußball-Bundesliga 2008–09: Goalkeeper Butt si...\n",
              "                             ...                        \n",
              "495    '90s Cartoons With Human Eyes May Ruin Your Ch...\n",
              "496    Wait, WTF Is \"I Saw Mommy Kissing Santa Claus\"...\n",
              "497           First Women Win Seats in Kuwait Parliament\n",
              "498                   Were You A Scene Kid Or An Emo Kid\n",
              "499    Opposition leader takes early lead in Sierra L...\n",
              "Name: Comment, Length: 500, dtype: object"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#https://github.com/anirudhshenoy/text-classification-small-datasets/tree/master/datasets\n",
        "\n",
        "df = pd.read_csv('book_title_test_data.csv')\n",
        "# Keep only the first 500 rows in df\n",
        "df = df.iloc[:500]\n",
        "\n",
        "# Rename 'title' column to 'Comment'\n",
        "df.rename(columns={'title': 'Comment'}, inplace=True)\n",
        "df['Comment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yb1DU3i4_2Vn"
      },
      "outputs": [],
      "source": [
        "# NEW CODE: LDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPswVk7a_9Nm",
        "outputId": "85c5caed-dc6d-4772-9a2d-ebee476cf91a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stop words and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess(text):\n",
        "    # Tokenize, remove stopwords and lemmatize\n",
        "    return [lemmatizer.lemmatize(word) for word in gensim.utils.simple_preprocess(text) if word not in stop_words]\n",
        "\n",
        "# Preprocess the column\n",
        "processed_docs = df['Comment'].map(preprocess)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-jKQSgoAO0u"
      },
      "outputs": [],
      "source": [
        "# Creating the term dictionary of our corpus, where every unique term is assigned an index\n",
        "dictionary = corpora.Dictionary(processed_docs)\n",
        "\n",
        "# Converting list of documents (corpus) into Document-Term Matrix using the dictionary\n",
        "doc_term_matrix = [dictionary.doc2bow(doc) for doc in processed_docs]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Bp7F8U1ARQO"
      },
      "outputs": [],
      "source": [
        "# Creating the LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=doc_term_matrix,\n",
        "                                            id2word=dictionary,\n",
        "                                            num_topics=3, # Change the number of topics\n",
        "                                            random_state=100,\n",
        "                                            update_every=1,\n",
        "                                            chunksize=100,\n",
        "                                            passes=10,\n",
        "                                            alpha='auto',\n",
        "                                            per_word_topics=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sI3PB55AUUH",
        "outputId": "03cce441-6778-442c-c15e-eea7fdfb1ee8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic: 0 \n",
            "Words: 0.026*\"care\" + 0.022*\"staff\" + 0.021*\"patient\" + 0.018*\"made\" + 0.017*\"hospital\" + 0.015*\"delay\" + 0.014*\"like\" + 0.012*\"problem\" + 0.011*\"feel\" + 0.011*\"professional\"\n",
            "Topic: 1 \n",
            "Words: 0.034*\"staff\" + 0.028*\"patient\" + 0.016*\"concern\" + 0.015*\"hospital\" + 0.011*\"abuse\" + 0.011*\"felt\" + 0.011*\"cleanliness\" + 0.010*\"great\" + 0.010*\"member\" + 0.009*\"room\"\n",
            "Topic: 2 \n",
            "Words: 0.055*\"time\" + 0.034*\"waiting\" + 0.030*\"care\" + 0.028*\"good\" + 0.022*\"doctor\" + 0.022*\"hospital\" + 0.019*\"staff\" + 0.018*\"wait\" + 0.014*\"room\" + 0.014*\"experience\"\n"
          ]
        }
      ],
      "source": [
        "# View the topics in LDA model\n",
        "for idx, topic in lda_model.print_topics(-1):\n",
        "    print('Topic: {} \\nWords: {}'.format(idx, topic))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wx5vJwcAXDc",
        "outputId": "f2e821ee-6764-4e0e-ca36-5bb7bfd5f1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHLNZClmA27L",
        "outputId": "80d72265-28fb-470e-d736-ac1577683d35"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Topic 0: care, staff, patient, made, hospital\n",
            "Topic 1: staff, patient, concern, hospital, abuse\n",
            "Topic 2: time, waiting, care, good, doctor\n"
          ]
        }
      ],
      "source": [
        "top_n = 5  # Set the number of top words you want to consider for each topic\n",
        "\n",
        "top_words_per_topic = []\n",
        "for t in range(lda_model.num_topics):\n",
        "    top_words = [word for word, prop in lda_model.show_topic(t, topn=top_n)]\n",
        "    top_words_per_topic.append(top_words)\n",
        "\n",
        "# Optionally, print the top words for each topic\n",
        "for idx, topic_words in enumerate(top_words_per_topic):\n",
        "    print(f\"Topic {idx}: {', '.join(topic_words)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gWsNejcA6IR",
        "outputId": "786a2c67-f929-4661-ada2-050ca23d918b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.coherencemodel:The currently set model 'LdaModel<num_terms=617, num_topics=3, decay=0.5, chunksize=100>' may be inconsistent with the newly set topics\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score:  0.5152452116001003\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "\n",
        "# Compute Coherence Score using the top N words of each topic\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, topics=top_words_per_topic, dictionary=dictionary, texts=processed_docs, coherence='c_v')\n",
        "#coherence_model_lda = CoherenceModel(model=lda_model, corpus=doc_term_matrix, topics=top_words_per_topic, dictionary=dictionary, coherence='u_mass')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('Coherence Score: ', coherence_lda)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

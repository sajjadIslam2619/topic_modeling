{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_4hHWSCeAbF"
      },
      "source": [
        "https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
        "\n",
        "Datasource: Private"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jo2JUO7bsugE",
        "outputId": "a8c7d3cc-0043-47b4-b48a-29285dbb64c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp312-cp312-macosx_10_9_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting pyLDAvis\n",
            "  Using cached pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl.metadata (61 kB)\n",
            "Collecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp312-cp312-macosx_10_9_x86_64.whl.metadata (60 kB)\n",
            "Collecting smart-open>=1.8.1 (from gensim)\n",
            "  Downloading smart_open-7.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting click (from nltk)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl.metadata (40 kB)\n",
            "Collecting tqdm (from nltk)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting pandas>=2.0.0 (from pyLDAvis)\n",
            "  Downloading pandas-2.2.3-cp312-cp312-macosx_10_9_x86_64.whl.metadata (89 kB)\n",
            "Collecting jinja2 (from pyLDAvis)\n",
            "  Downloading jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting numexpr (from pyLDAvis)\n",
            "  Downloading numexpr-2.10.2-cp312-cp312-macosx_10_13_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Using cached funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting scikit-learn>=1.0.0 (from pyLDAvis)\n",
            "  Downloading scikit_learn-1.6.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (31 kB)\n",
            "Requirement already satisfied: setuptools in /Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages (from pyLDAvis) (75.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Collecting pytz>=2020.1 (from pandas>=2.0.0->pyLDAvis)\n",
            "  Using cached pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas>=2.0.0->pyLDAvis)\n",
            "  Using cached tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.0.0->pyLDAvis)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting wrapt (from smart-open>=1.8.1->gensim)\n",
            "  Downloading wrapt-1.17.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->pyLDAvis)\n",
            "  Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Downloading gensim-4.3.3-cp312-cp312-macosx_10_9_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-macosx_10_9_x86_64.whl (20.3 MB)\n",
            "Downloading pandas-2.2.3-cp312-cp312-macosx_10_9_x86_64.whl (12.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl (288 kB)\n",
            "Downloading scikit_learn-1.6.0-cp312-cp312-macosx_10_13_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp312-cp312-macosx_10_9_x86_64.whl (39.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.4/39.4 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading smart_open-7.1.0-py3-none-any.whl (61 kB)\n",
            "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "Using cached funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Downloading jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
            "Downloading numexpr-2.10.2-cp312-cp312-macosx_10_13_x86_64.whl (145 kB)\n",
            "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp312-cp312-macosx_10_13_universal2.whl (14 kB)\n",
            "Using cached pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
            "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Using cached tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
            "Downloading wrapt-1.17.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pytz, funcy, wrapt, tzdata, tqdm, threadpoolctl, regex, numpy, MarkupSafe, joblib, click, smart-open, scipy, pandas, numexpr, nltk, jinja2, scikit-learn, gensim, pyLDAvis\n",
            "Successfully installed MarkupSafe-3.0.2 click-8.1.8 funcy-2.0 gensim-4.3.3 jinja2-3.1.5 joblib-1.4.2 nltk-3.9.1 numexpr-2.10.2 numpy-1.26.4 pandas-2.2.3 pyLDAvis-3.4.1 pytz-2024.2 regex-2024.11.6 scikit-learn-1.6.0 scipy-1.13.1 smart-open-7.1.0 threadpoolctl-3.5.0 tqdm-4.67.1 tzdata-2024.2 wrapt-1.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim nltk pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FL5PLlRteMA",
        "outputId": "a6cbd057-b0ea-41b9-d9de-94484b5c008c"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "import pyLDAvis.gensim_models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords', force=True)\n",
        "nltk.download('punkt', force=True)\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileSystemPathPointer('/Users/sajjadislam/nltk_data/tokenizers/punkt')"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.data.find('tokenizers/punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FileSystemPathPointer('/Users/sajjadislam/nltk_data/corpora/stopwords')"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.data.find('corpora/stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "nltk.data.path.append('/Users/sajjadislam/nltk_data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8R4IfSWpo5d",
        "outputId": "2e8026ec-9b2b-4c32-b510-f43bd3452741"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zEf2Pedoomux"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"../Data/patient_review_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The nurses were exceptionally compassionate an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I appreciated the clear communication from the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The cleanliness of the hospital was remarkable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My pain was managed well throughout my stay.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I felt rushed during my consultation.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Comment\n",
              "0  The nurses were exceptionally compassionate an...\n",
              "1  I appreciated the clear communication from the...\n",
              "2    The cleanliness of the hospital was remarkable.\n",
              "3       My pain was managed well throughout my stay.\n",
              "4              I felt rushed during my consultation."
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "#df = pd.read_csv(\"./Data/test_data.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed words: ['sample', 'sentence', 'testing', 'preprocessing']\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Test preprocessing function\n",
        "test_text = \"This is a sample sentence for testing preprocessing.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "try:\n",
        "    words = word_tokenize(test_text.lower())\n",
        "    processed_words = [word for word in words if word.isalpha() and word not in stop_words]\n",
        "    print(\"Processed words:\", processed_words)\n",
        "except Exception as e:\n",
        "    print(f\"Error in preprocessing: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "j_pvGkypqN4K",
        "outputId": "e00b2600-5a7e-4e8e-d393-5625e476fc33"
      },
      "outputs": [],
      "source": [
        "# Step 1: Preprocess Data\n",
        "def preprocess(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text.lower())\n",
        "    return [word for word in words if word.isalpha() and word not in stop_words]\n",
        "\n",
        "processed_data = df['Comment'].apply(preprocess)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hIzi0cgbwFq",
        "outputId": "60887a3a-8d1a-445e-d017-5e32d896ddcf"
      },
      "outputs": [],
      "source": [
        "# Create Dictionary and Corpus\n",
        "dictionary = corpora.Dictionary(processed_data)\n",
        "corpus = [dictionary.doc2bow(text) for text in processed_data]\n",
        "\n",
        "# Step 2: LDA Model Training\n",
        "lda_model = LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n",
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/joblib/externals/loky/backend/fork_exec.py:38: DeprecationWarning: This process (pid=30678) is multi-threaded, use of fork() may lead to deadlocks in the child.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el3067856515938084189951155\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el3067856515938084189951155_data = {\"mdsDat\": {\"x\": [-0.0908206390249569, -0.03897467685655213, 0.12979531588150905], \"y\": [0.08105106189062347, -0.10594986185094751, 0.024898799960323955], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [36.138758932101105, 35.14974943983517, 28.711491628063722]}, \"tinfo\": {\"Term\": [\"hospital\", \"staff\", \"waiting\", \"room\", \"cleanliness\", \"doctors\", \"long\", \"doctor\", \"time\", \"patient\", \"feel\", \"treatment\", \"everyone\", \"wait\", \"see\", \"appreciated\", \"times\", \"took\", \"care\", \"awful\", \"masks\", \"professional\", \"abuse\", \"provided\", \"made\", \"delayed\", \"thorough\", \"longer\", \"privacy\", \"concerns\", \"hospital\", \"everyone\", \"cleanliness\", \"awful\", \"see\", \"efficient\", \"left\", \"atmosphere\", \"throughout\", \"attitude\", \"mrsa\", \"standard\", \"issues\", \"easy\", \"violent\", \"evident\", \"healthcare\", \"cops\", \"environment\", \"protocols\", \"comforting\", \"one\", \"standards\", \"secure\", \"busy\", \"sure\", \"impressed\", \"navigate\", \"administrative\", \"procedures\", \"experienced\", \"patients\", \"good\", \"problem\", \"taking\", \"expected\", \"blood\", \"great\", \"excellent\", \"clean\", \"hate\", \"professional\", \"management\", \"staff\", \"patient\", \"care\", \"masks\", \"felt\", \"wearing\", \"received\", \"experience\", \"time\", \"made\", \"feel\", \"abuse\", \"hours\", \"caring\", \"rights\", \"overall\", \"unacceptable\", \"error\", \"making\", \"given\", \"caused\", \"instructions\", \"visit\", \"seemed\", \"communication\", \"helpful\", \"member\", \"department\", \"regarding\", \"concern\", \"poor\", \"argue\", \"happen\", \"coordination\", \"seriously\", \"frustrating\", \"misinformation\", \"stress\", \"verbal\", \"undue\", \"concerns\", \"staff\", \"health\", \"clear\", \"delay\", \"could\", \"made\", \"patient\", \"hipaa\", \"like\", \"times\", \"masks\", \"wearing\", \"professional\", \"experience\", \"care\", \"wait\", \"time\", \"great\", \"waiting\", \"clean\", \"good\", \"felt\", \"doctors\", \"long\", \"doctor\", \"took\", \"appreciated\", \"delayed\", \"thorough\", \"longer\", \"privacy\", \"room\", \"spent\", \"bit\", \"crowded\", \"nurses\", \"get\", \"rushed\", \"worth\", \"treatment\", \"done\", \"something\", \"plan\", \"options\", \"food\", \"kept\", \"nurse\", \"satisfied\", \"expectations\", \"exceeded\", \"disturbing\", \"much\", \"waiting\", \"time\", \"provided\", \"wait\", \"care\", \"felt\", \"grievance\", \"emergency\", \"times\", \"medical\", \"stay\", \"good\", \"clean\", \"management\", \"appointments\"], \"Freq\": [33.0, 43.0, 19.0, 12.0, 13.0, 8.0, 7.0, 7.0, 22.0, 18.0, 7.0, 7.0, 6.0, 10.0, 7.0, 4.0, 10.0, 4.0, 32.0, 5.0, 13.0, 13.0, 5.0, 7.0, 11.0, 3.0, 3.0, 3.0, 3.0, 6.0, 32.548361199809136, 6.065875296639015, 12.674217119393152, 5.190767161377042, 6.443326494383963, 3.161097496103889, 3.1451923603534624, 3.118839214603138, 3.1000557026422384, 3.0991663434784615, 3.0725869375882344, 2.4318627453463937, 2.43174849517674, 2.431649646377995, 2.431639845505598, 2.429812122816061, 2.429646628085018, 2.9921772201459107, 4.021006998502781, 1.7021063081524639, 1.702085306283042, 1.7020259409988103, 1.7019674157893552, 1.701856245893883, 1.701763557643502, 1.7017522166340144, 1.7017335949764605, 1.7017046123966586, 1.7016577082216169, 1.701315657774969, 3.183165700442339, 3.194336734800194, 9.473858168542522, 5.115567027650997, 2.1703322059491863, 2.969313464993767, 3.504944582674446, 4.448113616183721, 2.46616439861051, 5.922115540273135, 2.4416969407093267, 5.866364257731268, 3.9013851107006263, 12.228509285977893, 6.999630172173791, 8.54223708294099, 5.23860045912201, 5.663278420623026, 3.6717781128866864, 3.15586999079237, 3.444104127134318, 3.934217193155076, 3.252124638626112, 6.675971056712895, 4.582451989853969, 3.142095523740745, 3.1388383527668684, 3.1337231317567196, 3.1130122198748302, 3.1027175005445704, 2.4183932054570243, 2.4181202992511692, 2.4174633633544396, 2.416290574809117, 2.4158223854200296, 2.4020272763116726, 2.3922680196567736, 2.372438741894998, 2.350958681185429, 2.3338993197046403, 4.028300141898667, 1.6927386000639513, 1.692672416223609, 1.692669284066556, 1.6926555298116701, 1.6925452234110998, 1.6923860281243508, 1.6922296926331721, 1.6922083122567653, 1.6918211504088378, 1.6916895998126023, 1.6915799743157391, 1.6912192315316519, 4.878514368984595, 30.01530089255215, 3.2623425737135263, 3.217450864657735, 4.632020690293941, 5.062976085778251, 7.72815521379707, 11.658507357411574, 3.128213531319346, 6.1910412414413925, 6.600234954442826, 7.5384952057409835, 5.5327751312293065, 6.97279495854968, 4.851381173336169, 9.002270401598985, 4.313767114621922, 4.637997390674469, 3.3056769198101548, 4.2085704878321355, 3.5465681227977703, 3.5510070702459045, 3.152612762402526, 7.943830127932248, 7.226697286997521, 7.223603118969975, 3.753040719066782, 4.332491536786729, 3.0504908246403657, 3.043838185401963, 3.0100063457329305, 3.003948156952509, 10.099856554339324, 2.9523735729253495, 2.3417534840547525, 2.338638848421618, 2.3246011856230786, 2.324044333266669, 2.3137760470061446, 2.294929831737993, 5.708219866671152, 2.2556718518480916, 1.6434272580208407, 1.6434255894660372, 1.6433517281067371, 1.6432731947939874, 1.6431295878439025, 1.6426332484083652, 1.6411749315101365, 1.638015467371282, 1.63797430968613, 1.6376045579416818, 1.636709878856064, 15.266779889796432, 14.246184984489737, 4.778495790805011, 6.087441883235546, 14.720348214319243, 6.9728073184145805, 3.28182504691609, 2.455071270029336, 3.9050585202049883, 2.349423496775321, 2.346062137505247, 3.611682090961059, 2.8174580135747136, 2.4553858482282824, 2.3887738033643475], \"Total\": [33.0, 43.0, 19.0, 12.0, 13.0, 8.0, 7.0, 7.0, 22.0, 18.0, 7.0, 7.0, 6.0, 10.0, 7.0, 4.0, 10.0, 4.0, 32.0, 5.0, 13.0, 13.0, 5.0, 7.0, 11.0, 3.0, 3.0, 3.0, 3.0, 6.0, 33.55742145001538, 6.558011848597699, 13.832762959770832, 5.827639481911672, 7.284298049991582, 3.639182226457062, 3.6390275302419606, 3.638853227885151, 3.6370168617911225, 3.637038352474996, 3.636667535191182, 2.909390992338289, 2.909388184100768, 2.909383819769516, 2.9093847132474937, 2.909336139886317, 2.9093759461256936, 3.633302191963362, 5.078565161334611, 2.179583658906113, 2.179583323979068, 2.1795819724334016, 2.1795830789410466, 2.17958065033583, 2.179573619232486, 2.1795747123941265, 2.1795714739527066, 2.1795705357346487, 2.1795710025205297, 2.179568348320818, 4.344484158173309, 4.365036021950259, 16.636547329749483, 8.003990733690653, 2.90789413678093, 4.337101918234342, 5.7672334214947885, 8.000638730548998, 3.6352681503248014, 12.286141676645618, 3.6142718258797837, 13.088958611526206, 7.205328887747013, 43.57508542752548, 18.901805681159058, 32.264855698859215, 13.083806711339022, 15.788698501440134, 9.448099563379785, 6.491916662885877, 8.715683046285703, 22.818399568319283, 11.611492187926771, 7.250497156653588, 5.074437414196908, 3.623183634092555, 3.6232133564928586, 3.622909362945688, 3.6233103340878037, 3.6219723286236842, 2.89738994106248, 2.8973809688197574, 2.897385748423432, 2.8973965451299173, 2.8973939478825326, 2.8969056279184984, 2.89748444345772, 2.8960272222063437, 2.8954559123835137, 2.8949385206623255, 5.076366965829335, 2.1715875739087, 2.1715861708635975, 2.1715858397106302, 2.1715846927217326, 2.171581842273911, 2.171578029156729, 2.171575080492101, 2.171575061576597, 2.1715819592801853, 2.171583000267367, 2.1715547119303755, 2.171564870945751, 6.492220600077187, 43.57508542752548, 4.352238951048988, 4.351186353667231, 6.485040460678398, 7.203393501965228, 11.611492187926771, 18.901805681159058, 4.3272735832218245, 9.439060318047988, 10.770833480936314, 13.083806711339022, 9.448099563379785, 13.088958611526206, 8.715683046285703, 32.264855698859215, 10.70538397312786, 22.818399568319283, 8.000638730548998, 19.86507933824366, 12.286141676645618, 16.636547329749483, 15.788698501440134, 8.471910212092428, 7.767637174793913, 7.767728869592979, 4.243162572486026, 4.952119607753104, 3.5384905179661073, 3.5387387130105186, 3.5399279954374934, 3.5398313183729537, 12.043886383953536, 3.5419734538178567, 2.8340497185572886, 2.834106248989059, 2.834503415756815, 2.834675224930919, 2.835033531327143, 2.8353982141831047, 7.087462468704846, 2.8370792700459084, 2.129224010161877, 2.1292237870702344, 2.129225084569759, 2.1292256048916034, 2.1292291352629293, 2.1292520401068495, 2.1292936060128107, 2.1294000963718456, 2.12940160843087, 2.129413651789177, 2.129462181293482, 19.86507933824366, 22.818399568319283, 7.124471947993747, 10.70538397312786, 32.264855698859215, 15.788698501440134, 5.710126410636244, 4.285788993863753, 10.770833480936314, 4.293183645719349, 5.015126141257317, 16.636547329749483, 12.286141676645618, 7.205328887747013, 5.743646196369125], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.9164, -4.5965, -3.8596, -4.7523, -4.5361, -5.2483, -5.2533, -5.2617, -5.2678, -5.268, -5.2767, -5.5105, -5.5106, -5.5106, -5.5106, -5.5114, -5.5114, -5.3032, -5.0076, -5.8673, -5.8673, -5.8674, -5.8674, -5.8675, -5.8675, -5.8675, -5.8675, -5.8675, -5.8676, -5.8678, -5.2413, -5.2378, -4.1506, -4.7669, -5.6243, -5.3108, -5.145, -4.9067, -5.4965, -4.6205, -5.5065, -4.6299, -5.0378, -3.8954, -4.4533, -4.2542, -4.7431, -4.6652, -5.0985, -5.2499, -5.1625, -5.0295, -5.2199, -4.4729, -4.8492, -5.2265, -5.2276, -5.2292, -5.2358, -5.2391, -5.4883, -5.4884, -5.4887, -5.4892, -5.4894, -5.4951, -5.4992, -5.5075, -5.5166, -5.5239, -4.9781, -5.8451, -5.8451, -5.8451, -5.8451, -5.8452, -5.8453, -5.8454, -5.8454, -5.8456, -5.8457, -5.8458, -5.846, -4.7866, -2.9697, -5.189, -5.2028, -4.8384, -4.7495, -4.3266, -3.9154, -5.231, -4.5483, -4.4843, -4.3514, -4.6607, -4.4294, -4.7922, -4.174, -4.9096, -4.8371, -5.1758, -4.9343, -5.1054, -5.1042, -5.2232, -4.0967, -4.1913, -4.1918, -4.8465, -4.703, -5.0538, -5.056, -5.0672, -5.0692, -3.8566, -5.0865, -5.3182, -5.3195, -5.3256, -5.3258, -5.3302, -5.3384, -4.4272, -5.3557, -5.6723, -5.6723, -5.6724, -5.6724, -5.6725, -5.6728, -5.6737, -5.6756, -5.6756, -5.6759, -5.6764, -3.4434, -3.5126, -4.605, -4.3629, -3.4799, -4.2271, -4.9807, -5.271, -4.8068, -5.3149, -5.3164, -4.8849, -5.1333, -5.2708, -5.2983], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9873, 0.9398, 0.9303, 0.9021, 0.8951, 0.877, 0.872, 0.8636, 0.8581, 0.8578, 0.8493, 0.8385, 0.8385, 0.8384, 0.8384, 0.8377, 0.8376, 0.8237, 0.7843, 0.7705, 0.7705, 0.7705, 0.7705, 0.7704, 0.7703, 0.7703, 0.7703, 0.7703, 0.7703, 0.7701, 0.7068, 0.7056, 0.4547, 0.5702, 0.7253, 0.6389, 0.5198, 0.4308, 0.6298, 0.288, 0.6256, 0.2153, 0.4043, -0.2529, 0.0244, -0.3112, 0.1025, -0.0075, 0.0727, 0.2965, 0.0893, -0.7401, -0.2549, 0.963, 0.9436, 0.9031, 0.902, 0.9005, 0.8938, 0.8908, 0.8648, 0.8647, 0.8645, 0.864, 0.8638, 0.8582, 0.854, 0.8461, 0.8372, 0.8301, 0.8143, 0.7964, 0.7964, 0.7964, 0.7964, 0.7963, 0.7962, 0.7961, 0.7961, 0.7959, 0.7958, 0.7958, 0.7956, 0.7598, 0.6728, 0.7573, 0.7437, 0.709, 0.693, 0.6384, 0.5623, 0.7211, 0.6238, 0.5558, 0.4942, 0.5104, 0.4158, 0.4597, -0.2309, 0.1366, -0.5477, 0.1617, -0.5063, -0.1969, -0.4988, -0.5655, 1.1835, 1.1757, 1.1752, 1.1251, 1.1142, 1.0995, 1.0972, 1.0857, 1.0837, 1.0718, 1.0658, 1.0571, 1.0557, 1.0496, 1.0493, 1.0447, 1.0364, 1.0315, 1.0185, 0.9889, 0.9889, 0.9889, 0.9888, 0.9887, 0.9884, 0.9875, 0.9855, 0.9855, 0.9853, 0.9847, 0.9846, 0.7768, 0.8485, 0.6834, 0.4631, 0.4306, 0.694, 0.6907, 0.2333, 0.645, 0.4882, -0.2796, -0.2248, 0.1713, 0.3706]}, \"token.table\": {\"Topic\": [2, 1, 1, 2, 3, 3, 2, 1, 1, 1, 3, 1, 3, 1, 1, 2, 3, 2, 2, 1, 2, 3, 1, 3, 1, 2, 1, 2, 2, 2, 3, 2, 1, 2, 3, 3, 2, 3, 3, 1, 2, 3, 3, 3, 3, 1, 1, 1, 2, 3, 1, 3, 2, 1, 1, 3, 1, 2, 3, 1, 3, 1, 2, 1, 3, 2, 1, 2, 3, 3, 2, 3, 2, 1, 2, 3, 1, 2, 2, 3, 2, 1, 3, 1, 2, 1, 2, 2, 3, 1, 2, 2, 1, 2, 1, 3, 1, 1, 2, 3, 3, 1, 2, 3, 2, 1, 2, 3, 1, 2, 1, 3, 2, 2, 1, 3, 1, 3, 3, 1, 3, 2, 1, 2, 1, 2, 3, 2, 3, 1, 2, 1, 1, 2, 1, 1, 3, 1, 2, 3, 2, 2, 1, 3, 3, 3, 1, 1, 2, 2, 2, 3, 3, 1, 2, 3, 1, 1, 1, 2, 3, 2, 1, 1, 2, 3, 1, 1, 2, 3, 2, 3, 3, 2, 3, 2, 2, 2, 1, 2, 2, 3, 2, 3, 1, 2, 3], \"Freq\": [0.9853309030891478, 0.9176117674932968, 0.3482108632081673, 0.3482108632081673, 0.3482108632081673, 0.8077349330855311, 0.9209864145309117, 0.8244355603601954, 0.8248469521797887, 0.8579803221389088, 0.7057039214605335, 0.6935734532768841, 0.34678672663844207, 0.9176106658440282, 0.2789412754236558, 0.2789412754236558, 0.4649021257060931, 0.8279942981066655, 0.6902748618796055, 0.48835510430465173, 0.3255700695364345, 0.24417755215232587, 0.9397977857212824, 0.07229213736317557, 0.2298223791672789, 0.6894671375018366, 0.9176065801186168, 0.6906012432011245, 0.9209857876395662, 0.7701525114443207, 0.15403050228886414, 0.9209892406107294, 0.8256951504435313, 0.6941172932779393, 0.2776469173111757, 0.7056898451543272, 0.7710052127380176, 0.30840208509520706, 0.8478191434364428, 0.1969912748095878, 0.7879650992383512, 0.9392256869958353, 0.9011643065197245, 0.9442970711116786, 0.7049503414008016, 0.6874307839377625, 0.824361027647868, 0.23332926596054215, 0.23332926596054215, 0.4666585319210843, 0.7876240380755158, 0.19690600951887896, 0.690276435234187, 0.9149114302504624, 0.6874420499510072, 0.9392309990193798, 0.5501657421946453, 0.27508287109732266, 0.939231665954969, 0.691706133855696, 0.23056871128523201, 0.3442071016199341, 0.5736785026998902, 0.6905307720724632, 0.23017692402415438, 0.965451037185262, 0.38001865698130355, 0.19000932849065177, 0.4433550998115208, 0.9393086366260459, 0.9209904991946118, 0.705548199105857, 0.6902774340932233, 0.540977633256042, 0.24043450366935198, 0.24043450366935198, 0.49996008252775126, 0.37497006189581344, 0.35025494291590514, 0.5253824143738577, 0.9209876234301887, 0.5533618101657756, 0.2766809050828878, 0.22976679618176235, 0.6893003885452871, 0.687432644331622, 0.6907375075014068, 0.6932771737918134, 0.2310923912639378, 0.9833890261548947, 0.029799667459239232, 0.8280010904695327, 0.9176115690177165, 0.6902754806475785, 0.6874297527327584, 0.939307079204056, 0.824396071496752, 0.3178282476131485, 0.635656495226297, 0.9011749445140272, 0.8474748649878217, 0.25836472620799733, 0.6889726032213261, 0.08612157540266577, 0.6902785727948977, 0.5551446800439853, 0.13878617001099633, 0.27757234002199266, 0.3821517781722327, 0.6114428450755723, 0.46585475140206534, 0.46585475140206534, 0.6908609580912362, 0.9209875738067654, 0.8249310587150739, 0.9392042824565008, 0.9176119640128452, 0.9392969748661772, 0.7055909648519504, 0.917607149120936, 0.9393088661662696, 0.827972136909237, 0.37033498905226075, 0.634859981232447, 0.6872795516266156, 0.22909318387553854, 0.9393094385592773, 0.920985928084015, 0.8474980105489655, 0.6246883793797812, 0.3748130276278687, 0.9176128849278065, 0.4584016328630124, 0.5348019050068478, 0.9176064391140453, 0.28072255945413616, 0.7018063986353404, 0.46211314096974226, 0.15403771365658075, 0.3080754273131615, 0.9209851925981255, 0.8280637740163564, 0.16605935461701676, 0.8302967730850839, 0.7054590282266451, 0.9392786388651595, 0.917607705726255, 0.8236895248962162, 0.1372815874827027, 0.6902539216442851, 0.9209904911723245, 0.9393093401421617, 0.8469854557397462, 0.275386723451375, 0.6884668086284375, 0.022948893620947916, 0.6874290892035079, 0.9176066832798604, 0.19939677923022192, 0.39879355846044384, 0.39879355846044384, 0.9209871323148866, 0.9176102056181066, 0.6877829473579191, 0.34389147367895956, 0.8477596802980132, 0.8248518260986532, 0.17529713194932123, 0.21912141493665155, 0.6135399618226243, 0.6499032792949173, 0.37137330245423844, 0.9426930813203419, 0.14109422158008814, 0.8465653294805288, 0.8282780009917889, 0.9209948211811734, 0.9209991297995553, 0.687430572826367, 0.690391837664747, 0.37364376747630984, 0.5604656512144647, 0.20135837022806743, 0.7550938883552529, 0.4233655639599458, 0.6350483459399187, 0.7053682935947718], \"Term\": [\"abuse\", \"administrative\", \"appointments\", \"appointments\", \"appointments\", \"appreciated\", \"argue\", \"atmosphere\", \"attitude\", \"awful\", \"bit\", \"blood\", \"blood\", \"busy\", \"care\", \"care\", \"care\", \"caring\", \"caused\", \"clean\", \"clean\", \"clean\", \"cleanliness\", \"cleanliness\", \"clear\", \"clear\", \"comforting\", \"communication\", \"concern\", \"concerns\", \"concerns\", \"coordination\", \"cops\", \"could\", \"could\", \"crowded\", \"delay\", \"delay\", \"delayed\", \"department\", \"department\", \"disturbing\", \"doctor\", \"doctors\", \"done\", \"easy\", \"efficient\", \"emergency\", \"emergency\", \"emergency\", \"environment\", \"environment\", \"error\", \"everyone\", \"evident\", \"exceeded\", \"excellent\", \"excellent\", \"expectations\", \"expected\", \"expected\", \"experience\", \"experience\", \"experienced\", \"experienced\", \"feel\", \"felt\", \"felt\", \"felt\", \"food\", \"frustrating\", \"get\", \"given\", \"good\", \"good\", \"good\", \"great\", \"great\", \"grievance\", \"grievance\", \"happen\", \"hate\", \"hate\", \"health\", \"health\", \"healthcare\", \"helpful\", \"hipaa\", \"hipaa\", \"hospital\", \"hospital\", \"hours\", \"impressed\", \"instructions\", \"issues\", \"kept\", \"left\", \"like\", \"like\", \"long\", \"longer\", \"made\", \"made\", \"made\", \"making\", \"management\", \"management\", \"management\", \"masks\", \"masks\", \"medical\", \"medical\", \"member\", \"misinformation\", \"mrsa\", \"much\", \"navigate\", \"nurse\", \"nurses\", \"one\", \"options\", \"overall\", \"patient\", \"patient\", \"patients\", \"patients\", \"plan\", \"poor\", \"privacy\", \"problem\", \"problem\", \"procedures\", \"professional\", \"professional\", \"protocols\", \"provided\", \"provided\", \"received\", \"received\", \"received\", \"regarding\", \"rights\", \"room\", \"room\", \"rushed\", \"satisfied\", \"secure\", \"see\", \"see\", \"seemed\", \"seriously\", \"something\", \"spent\", \"staff\", \"staff\", \"staff\", \"standard\", \"standards\", \"stay\", \"stay\", \"stay\", \"stress\", \"sure\", \"taking\", \"taking\", \"thorough\", \"throughout\", \"time\", \"time\", \"time\", \"times\", \"times\", \"took\", \"treatment\", \"treatment\", \"unacceptable\", \"undue\", \"verbal\", \"violent\", \"visit\", \"wait\", \"wait\", \"waiting\", \"waiting\", \"wearing\", \"wearing\", \"worth\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el3067856515938084189951155\", ldavis_el3067856515938084189951155_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el3067856515938084189951155\", ldavis_el3067856515938084189951155_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el3067856515938084189951155\", ldavis_el3067856515938084189951155_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Step 3: Visualization\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(vis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Coherence Score: 0.47665848497832747\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Coherence Evaluation\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_data, dictionary=dictionary, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score:', coherence_lda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(0, '0.032*\"waiting\" + 0.031*\"care\" + 0.030*\"time\" + 0.021*\"room\" + 0.017*\"doctors\"')\n",
            "(1, '0.054*\"hospital\" + 0.021*\"cleanliness\" + 0.020*\"staff\" + 0.016*\"good\" + 0.014*\"care\"')\n",
            "(2, '0.051*\"staff\" + 0.020*\"patient\" + 0.015*\"care\" + 0.013*\"made\" + 0.013*\"masks\"')\n"
          ]
        }
      ],
      "source": [
        "num_words = 5\n",
        "topics = lda_model.print_topics(num_topics=-1, num_words=num_words)\n",
        "for topic in topics:\n",
        "    print(topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/pty.py:95: DeprecationWarning: This process (pid=30678) is multi-threaded, use of forkpty() may lead to deadlocks in the child.\n",
            "  pid, fd = os.forkpty()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rwalk/gsdmm.git\n",
            "  Cloning https://github.com/rwalk/gsdmm.git to /private/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/pip-req-build-y9495sb1\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rwalk/gsdmm.git /private/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/pip-req-build-y9495sb1\n",
            "  Resolved https://github.com/rwalk/gsdmm.git to commit 4ad1b6b6976743681ee4976b4573463d359214ee\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages (from gsdmm==0.1) (1.26.4)\n",
            "Building wheels for collected packages: gsdmm\n",
            "  Building wheel for gsdmm (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gsdmm: filename=gsdmm-0.1-py3-none-any.whl size=4588 sha256=379fd2ded88367de72e60dd85899705c143797242f29b93316aaebc538397a45\n",
            "  Stored in directory: /private/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/pip-ephem-wheel-cache-oljw591c/wheels/f4/09/2a/066df0c20da7602aa8ba0c8157aedeef56199c5384f0aa1d09\n",
            "Successfully built gsdmm\n",
            "Installing collected packages: gsdmm\n",
            "Successfully installed gsdmm-0.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/rwalk/gsdmm.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from gsdmm import MovieGroupProcess\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Preprocess the Data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def preprocess(text):\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = word_tokenize(text.lower())\n",
        "    return [word for word in words if word.isalpha() and word not in stop_words]\n",
        "\n",
        "processed_data = [preprocess(text) for text in df['Comment']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In stage 0: transferred 200 clusters with 5 clusters populated\n",
            "In stage 1: transferred 104 clusters with 5 clusters populated\n",
            "In stage 2: transferred 73 clusters with 5 clusters populated\n",
            "In stage 3: transferred 60 clusters with 5 clusters populated\n",
            "In stage 4: transferred 72 clusters with 5 clusters populated\n",
            "In stage 5: transferred 61 clusters with 5 clusters populated\n",
            "In stage 6: transferred 64 clusters with 5 clusters populated\n",
            "In stage 7: transferred 61 clusters with 5 clusters populated\n",
            "In stage 8: transferred 59 clusters with 5 clusters populated\n",
            "In stage 9: transferred 57 clusters with 5 clusters populated\n",
            "In stage 10: transferred 46 clusters with 5 clusters populated\n",
            "In stage 11: transferred 46 clusters with 5 clusters populated\n",
            "In stage 12: transferred 51 clusters with 5 clusters populated\n",
            "In stage 13: transferred 36 clusters with 5 clusters populated\n",
            "In stage 14: transferred 44 clusters with 5 clusters populated\n",
            "In stage 15: transferred 38 clusters with 5 clusters populated\n",
            "In stage 16: transferred 47 clusters with 5 clusters populated\n",
            "In stage 17: transferred 42 clusters with 5 clusters populated\n",
            "In stage 18: transferred 36 clusters with 5 clusters populated\n",
            "In stage 19: transferred 36 clusters with 5 clusters populated\n",
            "In stage 20: transferred 44 clusters with 5 clusters populated\n",
            "In stage 21: transferred 44 clusters with 5 clusters populated\n",
            "In stage 22: transferred 42 clusters with 5 clusters populated\n",
            "In stage 23: transferred 40 clusters with 5 clusters populated\n",
            "In stage 24: transferred 44 clusters with 5 clusters populated\n",
            "In stage 25: transferred 38 clusters with 5 clusters populated\n",
            "In stage 26: transferred 38 clusters with 5 clusters populated\n",
            "In stage 27: transferred 46 clusters with 5 clusters populated\n",
            "In stage 28: transferred 41 clusters with 5 clusters populated\n",
            "In stage 29: transferred 46 clusters with 5 clusters populated\n",
            "Document: ['nurses', 'exceptionally', 'compassionate', 'attentive'], Topic: (0, 0.9999438364373708)\n",
            "Document: ['appreciated', 'clear', 'communication', 'medical', 'staff'], Topic: (1, 0.9998409050811166)\n",
            "Document: ['cleanliness', 'hospital', 'remarkable'], Topic: (1, 0.9248434575574908)\n",
            "Document: ['pain', 'managed', 'well', 'throughout', 'stay'], Topic: (4, 0.9999405153320885)\n",
            "Document: ['felt', 'rushed', 'consultation'], Topic: (3, 0.994047305085509)\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the GSDMM model\n",
        "mgp = MovieGroupProcess(K=5, alpha=0.1, beta=0.1, n_iters=30)\n",
        "\n",
        "# Fit the model on the data\n",
        "vocab = set(x for doc in processed_data for x in doc)\n",
        "n_terms = len(vocab)\n",
        "y = mgp.fit(processed_data, n_terms)\n",
        "\n",
        "# To see the topics for the first 10 documents\n",
        "for i in range(5):\n",
        "    print(f\"Document: {processed_data[i]}, Topic: {mgp.choose_best_label(processed_data[i])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score: 0.45296388042690194\n"
          ]
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "# Assuming mgp is your fitted GSDMM model and processed_data is your documents\n",
        "\n",
        "# Find the dominant topic for each document\n",
        "doc_topic = [mgp.choose_best_label(doc) for doc in processed_data]\n",
        "\n",
        "# Word frequencies per topic\n",
        "topic_word_freq = defaultdict(lambda: defaultdict(int))\n",
        "for doc, topic in zip(processed_data, doc_topic):\n",
        "    for word in doc:\n",
        "        topic_word_freq[topic[0]][word] += 1\n",
        "\n",
        "# Extract top N words for each topic\n",
        "top_n = 5\n",
        "top_words_per_topic = {}\n",
        "for topic, word_freq in topic_word_freq.items():\n",
        "    top_words = sorted(word_freq, key=word_freq.get, reverse=True)[:top_n]\n",
        "    top_words_per_topic[topic] = top_words\n",
        "\n",
        "# Create a dictionary and corpus for coherence calculation\n",
        "dictionary = Dictionary(processed_data)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_data]\n",
        "\n",
        "# Using the top words for each topic to calculate coherence\n",
        "coherence_model = CoherenceModel(topics=list(top_words_per_topic.values()), \n",
        "                                 texts=processed_data, \n",
        "                                 dictionary=dictionary, \n",
        "                                 coherence='c_v')\n",
        "coherence_score = coherence_model.get_coherence()\n",
        "print('Coherence Score:', coherence_score)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py312_topic_modeling",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}

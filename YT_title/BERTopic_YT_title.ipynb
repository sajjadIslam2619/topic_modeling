{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from bertopic import BERTopic\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stop words\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('../Data/YT_title_test_data.csv')\n",
    "#df = pd.read_csv('../Data/YT_title_test_data_500.csv')\n",
    "documents = df['title']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 20:56:59,342 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text data...\n",
      "Training BERTopic model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 313/313 [00:08<00:00, 36.73it/s]\n",
      "2025-01-22 20:57:09,902 - BERTopic - Embedding - Completed ✓\n",
      "2025-01-22 20:57:09,903 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-01-22 20:57:15,189 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-01-22 20:57:15,190 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2025-01-22 20:57:15,598 - BERTopic - Cluster - Completed ✓\n",
      "2025-01-22 20:57:15,607 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-01-22 20:57:15,821 - BERTopic - Representation - Completed ✓\n",
      "2025-01-22 20:57:16,083 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-01-22 20:57:16,084 - BERTopic - Topic reduction - Reduced number of topics from 166 to 166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing topics to 2500...\n",
      "Extracting top words for each topic...\n",
      "Checking number of topics...\n",
      "Number of topics generated: 165\n",
      "Topic frequencies:\n",
      "     Topic  Count\n",
      "0       -1   3740\n",
      "11       0    391\n",
      "37       1    330\n",
      "20       2    167\n",
      "50       3    153\n",
      "..     ...    ...\n",
      "156    160     10\n",
      "159    161     10\n",
      "84     162     10\n",
      "139    163     10\n",
      "82     164     10\n",
      "\n",
      "[166 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Preprocess the text data\n",
    "def preprocess_text(texts):\n",
    "    return [simple_preprocess(doc, deacc=True) for doc in texts]\n",
    "\n",
    "print(\"Preprocessing text data...\")\n",
    "tokenized_docs = preprocess_text(documents)\n",
    "\n",
    "# Step 4: Train the BERTopic model\n",
    "print(\"Training BERTopic model...\")\n",
    "topic_model = BERTopic(language=\"english\", verbose=True)\n",
    "topics, probs = topic_model.fit_transform(documents)\n",
    "\n",
    "# Step 5: Reduce the number of topics\n",
    "desired_num_topics = 2500  # Change this value to the number of topics you want\n",
    "print(f\"Reducing topics to {desired_num_topics}...\")\n",
    "topic_model = topic_model.reduce_topics(documents, nr_topics=desired_num_topics)\n",
    "\n",
    "# Step 5: Extract top 10 words per topic\n",
    "print(\"Extracting top words for each topic...\")\n",
    "topic_words = topic_model.get_topics()\n",
    "\n",
    "# Step 5: Check the number of topics\n",
    "print(\"Checking number of topics...\")\n",
    "topic_freq = topic_model.get_topic_freq()  # Get the frequency of topics\n",
    "num_topics = len(topic_freq[topic_freq['Topic'] != -1])  # Exclude outlier (-1)\n",
    "print(f\"Number of topics generated: {num_topics}\")\n",
    "\n",
    "# Display topic frequencies\n",
    "print(\"Topic frequencies:\")\n",
    "print(topic_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dictionary and corpus...\n",
      "Calculating coherence score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score (Cv): 0.287265892633566\n",
      "\n",
      "Top 5 topics with their top words:\n",
      "Topic 0: the, you, to, of, your, that, are, and, this, from\n",
      "Topic 1: in, of, president, after, to, us, on, over, and, for\n",
      "Topic 2: to, in, iphone, million, of, for, is, apple, says, the\n",
      "Topic 3: of, the, championship, victory, for, out, in, cup, woods, win\n"
     ]
    }
   ],
   "source": [
    "# Prepare top words for coherence score calculation\n",
    "top_n_words = 10\n",
    "topic_word_lists = []\n",
    "for topic, words in topic_words.items():\n",
    "    if topic != -1:  # Exclude outlier topics\n",
    "        topic_word_lists.append([word[0] for word in words[:top_n_words]])\n",
    "\n",
    "# Check if there are topics generated\n",
    "if not topic_word_lists:\n",
    "    print(\"No valid topics were generated. Try increasing the sample size or adjusting model parameters.\")\n",
    "else:\n",
    "    # Step 6: Prepare corpus and dictionary for coherence calculation\n",
    "    print(\"Preparing dictionary and corpus...\")\n",
    "    dictionary = Dictionary(tokenized_docs)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "    # Step 7: Compute Coherence Score (Cv)\n",
    "    print(\"Calculating coherence score...\")\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists, \n",
    "        texts=tokenized_docs, \n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print(f\"Coherence Score (Cv): {coherence_score}\")\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nTop 5 topics with their top words:\")\n",
    "    for i, words in enumerate(topic_word_lists[:30]):\n",
    "        print(f\"Topic {i}: {', '.join(words)}\")\n",
    "\n",
    "    # Optional: Visualize topics\n",
    "    #print(\"Visualizing topics...\")\n",
    "    #topic_model.visualize_topics().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_topic_modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from bertopic import BERTopic\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.utils import simple_preprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the 20 Newsgroups dataset and create a DataFrame\n",
    "#print(\"Fetching 20 Newsgroups dataset...\")\n",
    "#newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "#df = pd.DataFrame({'text': newsgroups.data})\n",
    "#print(f\"Total documents: {len(df)}\")\n",
    "\n",
    "# Step 2: Take a random sample of 50 documents\n",
    "documents = pd.read_csv('../Data/20NewsGroup.csv')\n",
    "#documents = pd.read_csv('../Data/20NewsGroup_500.csv')\n",
    "\n",
    "documents.head()\n",
    "\n",
    "if 'Text' not in documents.columns:\n",
    "    raise ValueError(\"The CSV file does not contain a 'Text' column. Please check the column name.\")\n",
    "\n",
    "documents['Text'] = documents['Text'].astype(str).fillna('')\n",
    "# Convert to a list of strings for BERTopic\n",
    "texts = documents['Text'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-22 20:58:07,693 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training BERTopic model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 589/589 [02:18<00:00,  4.26it/s]\n",
      "2025-01-22 21:00:33,340 - BERTopic - Embedding - Completed ✓\n",
      "2025-01-22 21:00:33,344 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2025-01-22 21:00:39,728 - BERTopic - Dimensionality - Completed ✓\n",
      "2025-01-22 21:00:39,735 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "TOKENIZERS_PARALLELISMTOKENIZERS_PARALLELISM=(true | false)\n",
      "=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "2025-01-22 21:00:45,034 - BERTopic - Cluster - Completed ✓\n",
      "2025-01-22 21:00:45,068 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2025-01-22 21:00:48,399 - BERTopic - Representation - Completed ✓\n",
      "2025-01-22 21:00:50,109 - BERTopic - Topic reduction - Reducing number of topics\n",
      "2025-01-22 21:00:50,111 - BERTopic - Topic reduction - Reduced number of topics from 210 to 210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting top words for each topic...\n",
      "Checking number of topics...\n",
      "Number of topics generated: 209\n",
      "Topic frequencies:\n",
      "     Topic  Count\n",
      "2       -1   6424\n",
      "0        0   1848\n",
      "28       1    622\n",
      "49       2    473\n",
      "1        3    439\n",
      "..     ...    ...\n",
      "118    204     11\n",
      "204    205     10\n",
      "205    206     10\n",
      "183    207     10\n",
      "208    208     10\n",
      "\n",
      "[210 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Preprocess the text data\n",
    "def preprocess_text(texts):\n",
    "    return [simple_preprocess(doc, deacc=True) for doc in texts]\n",
    "\n",
    "print(\"Preprocessing text data...\")\n",
    "tokenized_docs = preprocess_text(texts)\n",
    "\n",
    "# Step 4: Train the BERTopic model\n",
    "print(\"Training BERTopic model...\")\n",
    "topic_model = BERTopic(language=\"english\", verbose=True)\n",
    "topics, probs = topic_model.fit_transform(texts)\n",
    "\n",
    "# Step 5: Reduce the number of topics\n",
    "desired_num_topics = 1500  # Change this value to the number of topics you want\n",
    "#print(f\"Reducing topics to {desired_num_topics}...\")\n",
    "topic_model = topic_model.reduce_topics(texts, nr_topics=desired_num_topics)\n",
    "\n",
    "# Step 5: Extract top 10 words per topic\n",
    "print(\"Extracting top words for each topic...\")\n",
    "topic_words = topic_model.get_topics()\n",
    "\n",
    "# Step 5: Check the number of topics\n",
    "print(\"Checking number of topics...\")\n",
    "topic_freq = topic_model.get_topic_freq()  # Get the frequency of topics\n",
    "num_topics = len(topic_freq[topic_freq['Topic'] != -1])  # Exclude outlier (-1)\n",
    "print(f\"Number of topics generated: {num_topics}\")\n",
    "\n",
    "# Display topic frequencies\n",
    "print(\"Topic frequencies:\")\n",
    "print(topic_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dictionary and corpus...\n",
      "Calculating coherence score...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coherence Score (Cv): 0.39039478011053835\n",
      "\n",
      "Top 5 topics with their top words:\n",
      "Topic 0: the, to, of, and, in, is, for, that, it, you\n",
      "Topic 1: the, in, to, is, of, that, and, be, game, he\n",
      "Topic 2: nan, consistently, wanted, know, just, to, , , , \n"
     ]
    }
   ],
   "source": [
    "# Prepare top words for coherence score calculation\n",
    "top_n_words = 10\n",
    "topic_word_lists = []\n",
    "for topic, words in topic_words.items():\n",
    "    if topic != -1:  # Exclude outlier topics\n",
    "        topic_word_lists.append([word[0] for word in words[:top_n_words]])\n",
    "\n",
    "# Check if there are topics generated\n",
    "if not topic_word_lists:\n",
    "    print(\"No valid topics were generated. Try increasing the sample size or adjusting model parameters.\")\n",
    "else:\n",
    "    # Step 6: Prepare corpus and dictionary for coherence calculation\n",
    "    print(\"Preparing dictionary and corpus...\")\n",
    "    dictionary = Dictionary(tokenized_docs)\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "\n",
    "    # Step 7: Compute Coherence Score (Cv)\n",
    "    print(\"Calculating coherence score...\")\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topic_word_lists, \n",
    "        texts=tokenized_docs, \n",
    "        dictionary=dictionary, \n",
    "        coherence='c_v'\n",
    "    )\n",
    "    coherence_score = coherence_model.get_coherence()\n",
    "    print(f\"Coherence Score (Cv): {coherence_score}\")\n",
    "\n",
    "    # Display results\n",
    "    print(\"\\nTop 5 topics with their top words:\")\n",
    "    for i, words in enumerate(topic_word_lists[:50]):\n",
    "        print(f\"Topic {i}: {', '.join(words)}\")\n",
    "\n",
    "    # Optional: Visualize topics\n",
    "    #print(\"Visualizing topics...\")\n",
    "    #topic_model.visualize_topics().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312_topic_modeling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

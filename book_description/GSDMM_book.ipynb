{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_4hHWSCeAbF"
      },
      "source": [
        "Source: https://towardsdatascience.com/end-to-end-topic-modeling-in-python-latent-dirichlet-allocation-lda-35ce4ed6b3e0\n",
        "\n",
        "Datasource: https://www.kaggle.com/datasets/elvinrustam/books-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8R4IfSWpo5d"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('../Data/BooksDataset.csv')\n",
        "df.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.dropna(subset=['Description'], inplace=True)\n",
        "df.dropna(subset=['Category'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypDck88P4nQV",
        "outputId": "d43fb1da-fd16-4933-f0e7-fe71c40f9b30"
      },
      "outputs": [],
      "source": [
        "# Keep only the first 500 rows in df\n",
        "#df = df.iloc[:500]\n",
        "df = df.sample(n=500, random_state=1)\n",
        "\n",
        "# Rename 'title' column to 'Comment'\n",
        "df.rename(columns={'Description': 'Comment'}, inplace=True)\n",
        "df['Comment']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(500, 2)"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPdbGoQx3rQM",
        "outputId": "d163d59b-1424-420a-e4d9-6c81e1206367"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/rwalk/gsdmm.git\n",
            "  Cloning https://github.com/rwalk/gsdmm.git to /private/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/pip-req-build-bii31zk3\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/rwalk/gsdmm.git /private/var/folders/p3/s4n39zb50rb2l96w9n054ch80000gn/T/pip-req-build-bii31zk3\n",
            "  Resolved https://github.com/rwalk/gsdmm.git to commit 4ad1b6b6976743681ee4976b4573463d359214ee\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy in /Users/sajjadislam/opt/anaconda3/envs/py312_topic_modeling/lib/python3.12/site-packages (from gsdmm==0.1) (1.26.4)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/rwalk/gsdmm.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zVSM02Tp3rQN"
      },
      "outputs": [],
      "source": [
        "from gsdmm import MovieGroupProcess\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import gensim\n",
        "from gensim import corpora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpz4pIbe3rQN",
        "outputId": "318e8a57-0923-4825-eb63-1f4d274106ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/sajjadislam/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "# Download stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Initialize stop words and lemmatizer\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# def preprocess(text):\n",
        "#     stop_words = set(stopwords.words('english'))\n",
        "#     words = word_tokenize(text.lower())\n",
        "#     return [word for word in words if word.isalpha() and word not in stop_words]\n",
        "\n",
        "def preprocess(text):\n",
        "    # Tokenize, remove stopwords and lemmatize\n",
        "    return [lemmatizer.lemmatize(word) for word in gensim.utils.simple_preprocess(text) if word not in stop_words]\n",
        "\n",
        "processed_data = [preprocess(text) for text in df['title']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGmR0BE83rQN",
        "outputId": "ab6e588c-bfcf-4e9b-86c3-83d93bf40a3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In stage 0: transferred 393 clusters with 10 clusters populated\n",
            "In stage 1: transferred 247 clusters with 10 clusters populated\n",
            "In stage 2: transferred 209 clusters with 10 clusters populated\n",
            "In stage 3: transferred 184 clusters with 10 clusters populated\n",
            "In stage 4: transferred 182 clusters with 10 clusters populated\n",
            "In stage 5: transferred 172 clusters with 10 clusters populated\n",
            "In stage 6: transferred 191 clusters with 10 clusters populated\n",
            "In stage 7: transferred 161 clusters with 10 clusters populated\n",
            "In stage 8: transferred 168 clusters with 10 clusters populated\n",
            "In stage 9: transferred 170 clusters with 10 clusters populated\n",
            "In stage 10: transferred 164 clusters with 10 clusters populated\n",
            "In stage 11: transferred 142 clusters with 10 clusters populated\n",
            "In stage 12: transferred 147 clusters with 10 clusters populated\n",
            "In stage 13: transferred 146 clusters with 10 clusters populated\n",
            "In stage 14: transferred 146 clusters with 10 clusters populated\n"
          ]
        }
      ],
      "source": [
        "# Create an instance of the GSDMM model\n",
        "# num_topics = k = 5\n",
        "mgp = MovieGroupProcess(K=10, alpha=0.1, beta=0.1, n_iters=15)\n",
        "\n",
        "# Fit the model on the data\n",
        "vocab = set(x for doc in processed_data for x in doc)\n",
        "n_terms = len(vocab)\n",
        "y = mgp.fit(processed_data, n_terms)\n",
        "\n",
        "# To see the topics for the first 10 documents\n",
        "#for i in range(5):\n",
        "    #print(f\"Document: {processed_data[i]}, Topic: {mgp.choose_best_label(processed_data[i])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOj1XHbS3rQN",
        "outputId": "c675c23b-5300-41ba-9f60-fc1b1a26258e"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.corpora.dictionary import Dictionary\n",
        "\n",
        "# Assuming mgp is your fitted GSDMM model and processed_data is your documents\n",
        "\n",
        "# Find the dominant topic for each document\n",
        "doc_topic = [mgp.choose_best_label(doc) for doc in processed_data]\n",
        "\n",
        "# Word frequencies per topic\n",
        "topic_word_freq = defaultdict(lambda: defaultdict(int))\n",
        "for doc, topic in zip(processed_data, doc_topic):\n",
        "    for word in doc:\n",
        "        topic_word_freq[topic[0]][word] += 1\n",
        "\n",
        "# Extract top N words for each topic\n",
        "top_n = 10\n",
        "top_words_per_topic = {}\n",
        "for topic, word_freq in topic_word_freq.items():\n",
        "    top_words = sorted(word_freq, key=word_freq.get, reverse=True)[:top_n]\n",
        "    top_words_per_topic[topic] = top_words\n",
        "\n",
        "# Create a dictionary and corpus for coherence calculation\n",
        "dictionary = Dictionary(processed_data)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_data]\n",
        "\n",
        "#list(top_words_per_topic.values())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FC78IV0M8NPW",
        "outputId": "946cc0eb-57e9-4400-8d9d-a1f6b238371b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coherence Score: 0.3819018753029405\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Using the top words for each topic to calculate coherence\n",
        "coherence_model = CoherenceModel(topics=list(top_words_per_topic.values()),texts=processed_data,dictionary=dictionary, coherence='c_v')\n",
        "#coherence_model = CoherenceModel(topics=list(top_words_per_topic.values()), corpus = corpus, dictionary=dictionary, coherence='u_mass')\n",
        "#coherence_model = CoherenceModel(topics=list(top_words_per_topic.values()), texts=processed_data, dictionary=dictionary, coherence='c_uci')\n",
        "coherence_score = coherence_model.get_coherence()\n",
        "print('Coherence Score:', coherence_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# No of data sample = 10000\n",
        "\n",
        "3 topic = Coherence Score: 0.3154939587778532\n",
        "\n",
        "5 topic = Coherence Score: 0.39488720656846593\n",
        "\n",
        "10 topic = Coherence Score: 0.3541673664052408\n",
        "\n",
        "15 topic = Coherence Score: 0.36738970687231437\n",
        "\n",
        "20 topic = Coherence Score: 0.3531226663611407\n",
        "\n",
        "25 topic = Coherence Score: 0.333633515439587\n",
        "\n",
        "30 topic = Coherence Score: 0.35206420000236205\n",
        "\n",
        "35 topic = Coherence Score: 0.35284489843398603\n",
        "\n",
        "40 topic = Coherence Score: 0.3301376346654848"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# No of data sample = top 500 | random 500 \n",
        "\n",
        "3 topic = Coherence Score: 0.46768588924709203 | Coherence Score: 0.4515472297700338\n",
        "\n",
        "5 topic = Coherence Score: 0.436618900342459 | Coherence Score: 0.3992964486716794\n",
        "\n",
        "10 topic = Coherence Score: 0.3809790533337555 | Coherence Score: 0.3819018753029405\n",
        "\n",
        "15 topic = Coherence Score: 0.3679961871652472\n",
        "\n",
        "20 topic = Coherence Score: 0.320415482006279\n",
        "\n",
        "25 topic = Coherence Score: 0.31854773646225865"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "py312_topic_modeling",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
